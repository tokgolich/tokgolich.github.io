<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>潘超：DeFi 的理论与实践</title>
    <url>/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<blockquote>
<p>编者注：本文为 MakerDAO 中国社区负责人潘超在 “洞见” 第四期活动 “DeFi” 上的演讲。在本文中，潘超极为精炼地总结出 DeFi 的定义、现在市场上不同 DeFi 项目的特点，并最终点出了去中心化金融的终极追求。简单的介绍中暗含着秩序感，清楚的结论还给人想象空间，这是他的 Insight。</p>
</blockquote>
<a id="more"></a>

<p>大家好，今天给大家分享的主题是《DeFi: 理论与实践》，我将介绍 DeFi 的定义、内核以及在具体领域的实践，最后聊一聊 DeFi 的再定义与方向。</p>
<h2 id="DeFi-的定义与内核"><a href="#DeFi-的定义与内核" class="headerlink" title="DeFi 的定义与内核"></a><strong>DeFi 的定义与内核</strong></h2><p>首先我们来谈一谈 DeFi 的定义。DeFi 的全称是 Decentralized Finance - 去中心化金融。</p>
<img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215024521.png" alt="image-20200222215024521" style="zoom:80%;">

<p>金融的概念我们一般都比较了解，那么去中心化呢？我们往往会想到以下的概念：分布式、透明性、抗审查、不可更改等。在我看来，以上这些并非去中心化金融的核心以及优势，分布式并非区块链独有，透明性、抗审查性以及不可更改对金融行业而言很难兼容。去中心化金融的核心和优势在于 <strong>无需准入</strong>。</p>
<p><strong>什么是无需准入？无需准入有三个层级：开发者的无需准入、节点的无需准入和用户的无需准入</strong>。</p>
<img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215124453.png" alt="image-20200222215124453" style="zoom:80%;">

<ul>
<li>开发者的无需准入意味着项目的代码开源，任何开发者都可以通过 Pull Request 的形式参与代码和协议的更新，一个例子是以太坊。</li>
<li>节点的无需准入指任何节点都可以作为矿工或者验证者，也就是说任何人都可以作为记账人。这往往指 Nakamoto Consensus 的全局共识机制，如工作量证明或者权益证明。</li>
<li>用户的无需准入是指任何人都可以使用这个网络，与这个网络进行互动，包括创建账户、转账、合约互动等。</li>
</ul>
<p><strong>个人认为，只需要满足使用者无需准入的金融项目都可以属于去中心化金融的范畴，而开发者以及节点的无需准入一般需要在效率、安全与去中心化中权衡</strong>。</p>
<p>围绕无需准入，还有“不可能三角”的特性：自动化、鲁棒性以及不可更改性。完全自动化、不可更改的网络如同火箭工程，在异常故障、恶意攻击和失误下保持系统的鲁棒性 (Robustness) 难度近乎苛刻。尤其是处在早期的去中心化金融项目，不可避免需要取舍。</p>
<h2 id="金融领域的去中心化"><a href="#金融领域的去中心化" class="headerlink" title="金融领域的去中心化"></a><strong>金融领域的去中心化</strong></h2><p>当我们在谈去中心化金融的时候，往往会将去中心化（区块链）作为主体，然后讨论和设计具有金融属性的应用和协议。但更加全面和系统地理解去中心化金融，我更倾向于以金融为体，思考哪些领域可以去中心化。在我看来，有以下几个方面和实例：</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215222939.png" alt="image-20200222215222939"></p>
<h3 id="融资"><a href="#融资" class="headerlink" title="融资"></a><strong>融资</strong></h3><p>融资是指项目向外界筹集资金，无需准入的融资则是完全意义上的众筹。传统的众筹 (Crowdfunding) 是以产品和服务为回报募集资金。而区块链上的融资则以代币为回报，募集代币或者法币，也就是 ICO（首次代币发行）。</p>
<p>尽管饱受争议，但是 ICO 可以说是区块链上的第一个具有金融属性的应用落地。最早的首次代币发行是 Mastercoin，试图在比特币网络的基础上开发金融协议。虽然 Mastercoin 本身失败了，但其通过 ICO 募集了 500 比特币，后来转型为大家熟知的 Tether 网络 - Omni。</p>
<p>在 Mastercoin 之后，我们又看到了包括以太坊在内的大型 ICO，尤其是在 ERC20 标准后，首次代币发行变得更加容易和受欢迎。</p>
<h3 id="商用金融软件"><a href="#商用金融软件" class="headerlink" title="商用金融软件"></a><strong>商用金融软件</strong></h3><p>不过，早期的区块链项目融资的软件设施非常的原生态，甚至简陋。投资人需要使用命令行和掌握基本的编程知识才能参与。这是一个很大的门槛。</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215337456.png" alt="image-20200222215337456"></p>
<p>随着（去中心化和中心化）商用软件的不断开发，区块链上的金融服务才不断让普通人得以方便使用。比如网页端的钱包 (Metamask)，手机端 imToken 和交易与支付的 DApp。</p>
<h3 id="存贷款"><a href="#存贷款" class="headerlink" title="存贷款"></a><strong>存贷款</strong></h3><p>有了外部资金和好用的软件，去中心化金融可以有规模化的采用和涉及金融的核心功能——基于稳定币的存贷款。</p>
<p>MakerDAO 是从2015年开始的项目，其发行的稳定币 Dai 成了以太坊上的基础货币和贷款引擎。如果将以太坊看做是黄金储备，那么 Dai 便是超额“以太坊本位”储备下发行的央行货币。</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215429710.png" alt="image-20200222215429710"></p>
<p><a href="https://mp.weixin.qq.com/s?biz=MzI4NTg4NzA3Mg==&mid=2247484564&idx=2&sn=2b7f775ea04ce47a840dfb7ae5d5a8e1&chksm=ebe41b9bdc93928d1d3a0c15daabf8b4292f66cc3ff5662c46c35dc4effde9b4257fb6fa0617&mpshare=1&scene=21&srcid=0401YZwmb9V6l4NuwYtS2IDo&key=fd47cfb2e36ff9534a83d2dccbf60b865974b82c7f365807cab31c2363da4049bef3ac4f5150f43ff26bff172688b41a8eb943ad39472ad0cf6eed0da30cfa6ad170ce749ba6797e0f3ee7b0b20f11d2&ascene=1&uin=Mjc4MjA1NTcyNA==&devicetype=Windows%2010&version=62060739&lang=zh_CN&pass_ticket=1/s%20pPjP1rtD2q8UhidykDK38ejkDodC1RjdZmTcX%20Z%20Am9ZkwPdQGc6hypgYkK5#wechat_redirect" target="_blank" rel="noopener">深入浅出理解 MakerDAO</a></p>
<p>在 Dai 作为“高能货币”的背景下，市场上出现了以其他资产为储备发行的衍生货币。比如以无需托管资金池、根据供需自动调节利率的“商业银行” Compound。</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215641556.png" alt="image-20200222215641556"></p>
<p>而点对点形式的借贷协议，也有 Dharma 等为代表。</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215701959.png" alt="image-20200222215701959"></p>
<h3 id="衍生品"><a href="#衍生品" class="headerlink" title="衍生品"></a><strong>衍生品</strong></h3><p>在基础货币和贷款之外，这个生态里自然地出现了衍生品，比如保证金交易 (dYdX) 和二元期权 (Augur) 等。</p>
<p>在中心化的保证金交易市场里，配资仅限于买入标的资产（即需要对手方），且只有在平仓时才会结算。基于公链的衍生品不需要对手方且可自由流通。</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215727632.png" alt="image-20200222215727632"></p>
<p>预测市场是二元期权的一种形式，由于只需要在结算时提供公认的结果，区块链账本的透明和智能合约的自动执行和结算的特点是天然的优势。</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215752651.png" alt="image-20200222215752651"></p>
<p><strong>还有许多将传统资产隐射到链上的金融合成品，如美股指数，让普通人可以不受限地、低成本地参与之前无法获得的衍生品投资</strong>。</p>
<h3 id="投资管理"><a href="#投资管理" class="headerlink" title="投资管理"></a><strong>投资管理</strong></h3><p>在有了相对丰富的金融产品后，投资管理是另一个可以去中心化实现的领域。通过自动执行的合约和无需准入的网络，基于区块链的协议（如 Melonport）可以将过去只属于证券公司的蛋糕分给专业的独立投资人。</p>
<h3 id="交易与支付"><a href="#交易与支付" class="headerlink" title="交易与支付"></a><strong>交易与支付</strong></h3><p>最后我们看一下交易与支付领域。去中心化交易所相信对大家来说已经不是陌生事，往往被人们忽视的一点，在区块链上的金融应用，无需托管的去中心化交易反而能够提供更快、更安全的清结算和流动性。</p>
<p><strong>就支付而言，二层甚至多层网络</strong>，即通过质押资产或者状态通道的方式，将一部分追求速度的交易放在链下进行，把要求交易安全和最终性的交易放在主链，<strong>已经相对成熟</strong>。我们已经看到一些接近主流支付工具的去中心化支付解决方案。</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215822023.png" alt="image-20200222215822023"></p>
<h2 id="去中心化金融的再定义与方向"><a href="#去中心化金融的再定义与方向" class="headerlink" title="去中心化金融的再定义与方向"></a><strong>去中心化金融的再定义与方向</strong></h2><p>带着这些实例回到最初的讨论，我们看到 DeFi 的核心是围绕着无需准入、低门槛进行的。<strong>去中心化金融的目标不是去中心化本身，而是更加开放和公平。</strong></p>
<p>这 Open Banking 很是接近。只是 Open Banking 给第三方的权限仅在于可读的 API，而 DeFi 给普通用户可读、可控甚至作为记账人的权力。</p>
<p>DeFi 与传统 FinTech 的区别在于后者基于数据与机器学习算法，实现更精准的信用评估和预测，而 DeFi 则是对所有参与者一视同仁，这既是初衷，但不得不承认的是，身份和信用体系是目前 DeFi 缺失的一环。</p>
<p>可以预见的是，去中心化金融将和传统金融同时存在，去中心化金融将很好地补充中心化机构在跨境领域、利基市场和缺乏金融基础设施地区的支付、贷款与信用。</p>
<p><strong>Bank the unbanked, Serve the underserved.</strong></p>
<p>去中心化金融 (Decentralized Finance) 更好的名字应该是开放式金融 (Open Finance)。</p>
<p><img src="/2020/02/22/DeFi-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20200222215903278.png" alt="image-20200222215903278"></p>
]]></content>
      <categories>
        <category>区块链</category>
        <category>DeFi</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>DeFi</tag>
        <tag>MakerDAO</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是DAO?</title>
    <url>/2020/02/22/%E4%BB%80%E4%B9%88%E6%98%AFDAO/</url>
    <content><![CDATA[<p><em>前言：区块链上有不少让人兴奋的概念，DAO是其中之一。为什么DAO会引起这么大的关注？其中很重要的原因是它具有的特性：自动化执行的统一规则、透明度、权益相关者都可以表达自己的利益诉求，它代表了一种组织管理的可能方向。但同时DAO发展处于初级阶段，它的治理机制是否合理？如何才能对组织发展有利？这里有很多细节需要探讨。本文作者是Delton Rhodes，由“蓝狐笔记”社群的“SIEN”翻译。</em></p>
<a id="more"></a>

<p>从历史看，组织的概念一直以来都是以严格的所有权结构为中心。在过去的几十年，公司开始引入开放、扁平的组织结构，它允许公司里的更多人可以表达自己的声音。但是，最终而言，为整个组织做决策通常是一个人或少数人的责任。</p>
<p>当我们观察大公司，明确的层级结构是标准。毕竟，Apple、Google以及Facebook都有CEO、CTO以及CMO，同时还有总监、经理以及相应的下属。早期的初创公司和大公司都有明确定义的所有权和领导结构。尽管在一家公司拥有股权是可能的，且理论上可以拥有组织的一部分，但其影响力是非常有限的。</p>
<p>几个世纪以来，确定所有权、层级以及规则的困境给组织发展带来了主要障碍。但是，如果公司不一定需要所有者怎么办？这个问题在历史上的大多数时侯都是基于理想主义的。而如今实现分布式的无所有者组织成为可能，这要感谢DAO（分布式自主组织）的出现。</p>
<h1 id="什么是DAO？"><a href="#什么是DAO？" class="headerlink" title="什么是DAO？"></a><strong>什么是DAO？</strong></h1><p>DAO有时候也称为分布式自治公司（DAC，decentralized autonomous corporation），它是一种由编码为计算机程序的规则所表示的组织，该程序是透明的、由股东或代币持有人控制，且不受中心机构影响。DAO利用区块链来验证交易。</p>
<p>DAO中的每个人都可以发布提议并进行投票来做决策。加密货币用来代表关键价值，在指定时期结束时具有最高数额的投票获胜。这跟其他形式的投票形成直接对比，这些投票通常每人的比重相同。通常，提案为“是或否”的问题，即公司A是否应该开发产品x？</p>
<h1 id="为什么人们想要这个？"><a href="#为什么人们想要这个？" class="headerlink" title="为什么人们想要这个？"></a><strong>为什么人们想要这个？</strong></h1><h2 id="快速、无边界的业务决策"><a href="#快速、无边界的业务决策" class="headerlink" title="快速、无边界的业务决策"></a><strong>快速、无边界的业务决策</strong></h2><p>如果在A国的某人想跟B国、C国等国家的创始人一起创业，当前做个事情的过程非常复杂。不同的司法管辖区有不同的要求。决策所需的时间范围也有所不同。例如，假设A国的某人只需一天即可正式成立业务，而在B国的那位需要3个月时间来启动。显然，在B国的人并不拥有跟A国的那位一样的资源。</p>
<p>DAO则提供了一种解决方案，可以通过遵守一套标准规则，让每个人都可以在同等条件下工作，而不用考虑所在的地理位置。本质上说，创建DAO的一个主要原因之一是为组织的成立和运营提供平等的体系。</p>
<h2 id="组织范围内的投票"><a href="#组织范围内的投票" class="headerlink" title="组织范围内的投票"></a><strong>组织范围内的投票</strong></h2><p>很多公司都有董事会来做重要决策。这么做的问题是这些组织通常只对少数选出的问题进行投票，且并不一定代表组织的大多数。DAO可以改变这一点，它允许组织的任何人都可以就他们关心的问题进行投票。例如，A可能会关心问题A和问题C，但不怎么关心问题B。</p>
<p>通过DAO，A可以根据自己关心的程度来对提案进行相应比例的代币投票。DAO不会使用对组织内成员的输入忽略或不加计入的系统，而是确保所有投票都被统计并向所有人显示。（蓝狐笔记：DAO确保组织内的利益相关者，也就是代币持有人都有机会表达的自己的意见）</p>
<h2 id="无法篡改规则"><a href="#无法篡改规则" class="headerlink" title="无法篡改规则"></a><strong>无法篡改规则</strong></h2><p>在任何组织内，政策和规则决定什么能做以及什么不能做。例如，在一家公司，不遵守规定的员工可能会遭受惩罚。如果某人上班迟到，这可能会也可能不会导致相应地扣减工资。这个决定可以通过时间戳来自动执行，但并非所有组织都会强制执行。</p>
<p>例如，如果老板迟到，它可能会通过设置例外情况来变更这个规则。在DAO中，它会通过代码确保规则适用于每个人。组织内已建立的一套规则无法被篡改，除非投票人群体同意这么做。</p>
<p>会议是形成想法和讨论想法的机会。DAO可以让远程组织更容易评估成员兴趣，更容易让想法从构想变为现实。</p>
<h1 id="DAO的局限"><a href="#DAO的局限" class="headerlink" title="DAO的局限"></a><strong>DAO的局限</strong></h1><h2 id="很多决策依赖于人的活动，而不是自动化"><a href="#很多决策依赖于人的活动，而不是自动化" class="headerlink" title="很多决策依赖于人的活动，而不是自动化"></a><strong>很多决策依赖于人的活动，而不是自动化</strong></h2><p>智能合约已经实现让很多人工任务变成自动化执行。例如，智能合约可以决定A是否可以向B发送资金，这个决定基于它是否满足一组标准。问题在于，无法仅通过点击按钮来完成很多活动。</p>
<p>其中一个案例是关于分配工作资金。例如，DAO可以使用智能合约来发送资金，开发团队用该资金构建APP。但是，DAO无法确保开发团队完成开发或者甚至无法确定资金是否被正确使用。最小化此类问题的机制可能包括要求通过里程碑来对大型项目是否完成进行投票。</p>
<h2 id="缺乏法律支持"><a href="#缺乏法律支持" class="headerlink" title="缺乏法律支持"></a><strong>缺乏法律支持</strong></h2><p>尽管由于DAO的无边界性质，它被认为在组织业务运营上更有效率，但这也可以看作为是一种缺陷。由于对DAO运作相关的官方法律还未制定，因此这类组织的法律地位充其量是模凌两可的。智能合约代码看上去有助于保护个人，但法院并没有正式认可这些。</p>
<p>DAO当前并不享有跟其他类型组织同等的法律保护</p>
<h1 id="当前最具人气的DAO"><a href="#当前最具人气的DAO" class="headerlink" title="当前最具人气的DAO"></a><strong>当前最具人气的DAO</strong></h1><ul>
<li>Dash DAO</li>
</ul>
<p>DashDAO由主节点（持有至少1000个DASH代币的权益持有者）管理。主节点可以运行重要功能，包括即时发送（InstantSend）和隐私发送（PrivateSend）。他们同时也为使用Dash国库资金的提案进行投票。任何人可以向主节点提交提案。5个DASH的费用是必须的，作为反垃圾发送的费用。如果有足够的主节点投票，则就可以为该提案提供资金。</p>
<ul>
<li>BitShares</li>
</ul>
<p>BitShares于2013年发布，它是第一个通过代表和见证人选举程序实现DAO的平台。代表向平台提交更新和改进。见证人验证交易并将其发布到区块链上。任何持有BTS代币的人，也就是持有平台原生代币的人，都可以进行投票。</p>
<ul>
<li>Aragon</li>
</ul>
<p>Aragon有一个DAO，它允许其代币ANT持有人创建属于他们自己的DAO组织，并就决策进行投票。其他功能还包括开采新代币、向用户支付各种代币、以及为组织内的个人定制权限的设置。像Liverpeer、MyBit、以及BrightID等项目都使用了Aragon。</p>
<ul>
<li>MakerDAO</li>
</ul>
<p>MakerDAO使用了这样的DAO：其原生代币MKR的持有人可以就影响其P2P借贷协议的决策进行投票。MKR代币持有人投票决定年化借贷利率（稳定费）、开启每个CDP所需的抵押资产比率（抵押率）、在ETH闪崩或其他无法意料情况下关闭协议的能力。</p>
<ul>
<li>Moloch DAO</li>
</ul>
<p>Moloch DAO的成员从DAO资助的公共物品的改善中享受到集体利益。Moloch DAO当前专注于资助以太坊2.0的开发。</p>
<ul>
<li>DAOStack</li>
</ul>
<p>DAOStack为Alchemy提供功能，它是首个基于DAOStack构建的实时去中心化应用。Alchemy当前正在为ETHGlobal、Kyber以及Polkadot这些组织管理实时DAO。当投票结束，预测正确的人们可以从其质押权益中获得收益。GEN是DAOStack的原生代币，旨在帮助去中心化组织有效扩展的同时不损害其价值。</p>
<h1 id="财富500强公司能否变成分布式的组织？"><a href="#财富500强公司能否变成分布式的组织？" class="headerlink" title="财富500强公司能否变成分布式的组织？"></a><strong>财富500强公司能否变成分布式的组织？</strong></h1><p>2017年，西门子成为第一家在其内部使用DAO的财富500强公司。完全在DAO上运行大公司的概念很让人感兴趣，但还不太实用。如果一家财富500强公司今天突然决定就其所有治理全部转向DAO，这会带来无数的技术挑战（UI/UX、安全、扩展性）需要解决，以使得区块链能支持此类组织结构。上述提及的局限性也将适用。对于参与者来说，这里会有学习曲线。</p>
<p>最后，还有人为因素需要考虑。如果参与率太低，就很难分辨出投票是否实际上代表组织的真正大多数。对于DAO提案和投票过于依赖，也可能会导致个人持续进行很多小决策，这从根本上限制了投票人实际上必须完成所分配任务的时间。从现实角度，因为上述原因，创建运行在DAO上的小型组织更有可行性。（蓝狐笔记：作者认为DAO上运行较大组织暂时不太可行，所以财富500强公司在DAO上运行还不现实）</p>
]]></content>
      <categories>
        <category>区块链</category>
        <category>DeFi</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>DeFi</tag>
        <tag>DAO</tag>
        <tag>分布式自治</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark On Yarn原理</title>
    <url>/2020/02/21/Spark-On-Yarn%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="Spark-资源管理架构"><a href="#Spark-资源管理架构" class="headerlink" title="Spark 资源管理架构"></a>Spark 资源管理架构</h1><p>首先介绍 Spark 的资源管理架构。Spark 集群考虑到了未来对接一些更强大的资源管理系统（如 Yarn、Mesos 等）没有在资源管理的设计上对外封闭，所以Spark 架构设计时将资源管理抽象出了一层，通过这种抽象能够构建一种插件式的资源管理模块。</p>
 <a id="more"></a>

<img src="/2020/02/21/Spark-On-Yarn%E5%8E%9F%E7%90%86/image-20200221231422026.png" alt="image-20200221231422026" style="zoom:50%;">

<p>如图所示是 Spark 的资源管理架构图。Master 是 Spark 的 主控节点，在实际的生产环境中会有多个 Master，只有一个 Master 处于 active 状态。Worker 是 Spark 的工作节点，向 Master 汇报自身的资源、Executeor 执行状态的改变，并接受 Master 的命令启动 Executor 或 Driver。Driver 是应用程序的驱动程序，每个应用包括许多小任务，Driver 负责推动这些小任务的有序执行。Executor 是 Spark 的工作进程，由 Worker 监管，负责具体任务的执行。</p>
<p>以上就是 Spark 在资源管理上的抽象出来的架构，这个架构跟 Yarn 的架构十分相似，因此 Spark 很容易地构建于 Yarn 之上。在 Spark 和 Yarn 两边的角色对比中：Master 和 ResourceManager 对应，Worker 和 NodeManager 对应，Driver 和 App Master 对应，Executor 和 Container 对应。</p>
<p>根据 Spark 部署模式的不同资源管理架构也会有不同的形态。Spark 大致包括四种部署模式：</p>
<ul>
<li><strong>Local 模式</strong>：部署在同一个进程上，只有 Driver 角色。接受任务后创建 Driver 负责应用的调度执行，不涉及 Master 和 Worker；</li>
<li><strong>Local-Cluster 模式</strong>：部署在同一个进程上，存在 Master 和 Worker 角色，它们作为独立线程存在于这个进程内；</li>
<li><strong>Standalone 模式</strong>：Spark 真正的集群模式，在这个模式下 Master 和 Worker 是独立的进程；</li>
<li><strong>第三方部署模式</strong>：构建于 Yarn 或 Mesos 之上，由它们提供资源管理。</li>
</ul>
<h1 id="Spark-on-Yarn"><a href="#Spark-on-Yarn" class="headerlink" title="Spark on Yarn"></a>Spark on Yarn</h1><h2 id="Spark-on-Yarn-Cluster"><a href="#Spark-on-Yarn-Cluster" class="headerlink" title="Spark on Yarn-Cluster"></a>Spark on Yarn-Cluster</h2><img src="/2020/02/21/Spark-On-Yarn%E5%8E%9F%E7%90%86/image-20200221231532301.png" alt="image-20200221231532301" style="zoom:80%;">

<p>客户端提交一个任务给 Yarn ResourceManager 后，App Manager 接受任务并找到一个 Container 创建App Master，此时 App Master 上运行的是 Spark Driver。之后 App Master 申请 Container 并启动，Spark Driver 在 Container 上启动 Spark Executor，并调度 Spark Task 在 Spark Executor 上运行，等到所有的任务执行完毕后，向 App Manager 取消注册并释放资源。</p>
<p>可以看出这个执行流程和 Yarn 对一个任务的处理过程几乎一致，不同的是在 Spark on Yarn 的 Job 处理过程中 App Master、Container 是交由 Spark 相对应的角色去处理的。</p>
<h2 id="Spark-on-Yarn-Client"><a href="#Spark-on-Yarn-Client" class="headerlink" title="Spark on Yarn-Client"></a>Spark on Yarn-Client</h2><img src="/2020/02/21/Spark-On-Yarn%E5%8E%9F%E7%90%86/image-20200221231547333.png" alt="image-20200221231547333" style="zoom:80%;">

<p>Spark on Yarn 还有另外一种运行模式：Spark on Yarn-Client。不同于上述的 Spark on Yarn-Cluster，Spark on Yarn-Client 的客户端在提交完任务之后不会将 Spark Driver 托管给 Yarn，而是在客户端运行。App Master 申请完 Container 之后同样也是由 Spark Driver 去启动 Spark Executor，执行任务。</p>
<h2 id="yarn-cluster和yarn-client模式的区别"><a href="#yarn-cluster和yarn-client模式的区别" class="headerlink" title="yarn-cluster和yarn-client模式的区别"></a>yarn-cluster和yarn-client模式的区别</h2><p><strong>从广义上讲</strong>，yarn-cluster适用于生产环境；而yarn-client适用于交互和调试，也就是希望快速地看到application的输出。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">在我们介绍yarn-cluster和yarn-client的深层次的区别之前，我们先明白一个概念：Application Master。在YARN中，每个Application实例都有一个Application Master进程，它是Application启动的第一个容器。它负责和ResourceManager打交道，并请求资源。获取资源之后告诉NodeManager为其启动container。</span><br></pre></td></tr></table></figure>

<p><strong>从深层次的含义讲</strong>，yarn-cluster和yarn-client模式的区别其实就是Application Master进程的区别，yarn-cluster模式下，driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行。然而yarn-cluster模式不适合运行交互类型的作业。而yarn-client模式下，Application Master仅仅向YARN请求executor，client会和请求的container通信来调度他们工作，也就是说Client不能离开。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Spark</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title>Yarn原理详解</title>
    <url>/2020/02/21/Yarn%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="经典-MapReduce-的局限性"><a href="#经典-MapReduce-的局限性" class="headerlink" title="经典 MapReduce 的局限性"></a>经典 MapReduce 的局限性</h1><p>经典 MapReduce 的最严重的限制主要关系到可伸缩性、资源利用和对与 MapReduce 不同的工作负载的支持。在 MapReduce 框架中，作业执行受两种类型的进程控制：</p>
<ul>
<li>一个称为 <em>JobTracker</em> 的主要进程，它协调在集群上运行的所有作业，分配要在 <em>TaskTracker</em> 上运行的 map 和 reduce 任务。</li>
<li>许多称为 <em>TaskTracker</em> 的下级进程，它们运行分配的任务并定期向 <em>JobTracker</em> 报告进度。</li>
</ul>
<a id="more"></a>

<h2 id="Apache-Hadoop-的经典版本-MRv1"><a href="#Apache-Hadoop-的经典版本-MRv1" class="headerlink" title="Apache Hadoop 的经典版本 (MRv1)"></a>Apache Hadoop 的经典版本 (MRv1)</h2><p><img src="/2020/02/21/Yarn%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/image-20200221230505637.png" alt="image-20200221230505637"></p>
<p>大型的 Hadoop 集群显现出了由单个 JobTracker 导致的可伸缩性瓶颈。在集群中有 5,000 个节点和 40,000 个任务同时运行时，这样一种设计实际上就会受到限制。由于此限制，必须创建和维护更小的、功能更差的集群。</p>
<p>此外，较小和较大的 Hadoop 集群都从未最高效地使用他们的计算资源。在 Hadoop MapReduce 中，每个从属节点上的计算资源由集群管理员分解为固定数量的 map 和 reduce slot，这些 slot 不可替代。设定 map slot 和 reduce slot 的数量后，节点在任何时刻都不能运行比 map slot 更多的 map 任务，即使没有 reduce 任务在运行。这影响了集群的利用率，因为在所有 map slot 都被使用（而且我们还需要更多）时，我们无法使用任何 reduce slot，即使它们可用，反之亦然。</p>
<p>最后但同样重要的是，Hadoop 设计为仅运行 MapReduce 作业。随着替代性的编程模型（比如 Apache Giraph 所提供的图形处理）的到来，除 MapReduce 外，越来越需要为可通过高效的、公平的方式在同一个集群上运行并共享资源的其他编程模型提供支持。</p>
<h1 id="为什么会有-Yarn-？"><a href="#为什么会有-Yarn-？" class="headerlink" title="为什么会有 Yarn ？"></a>为什么会有 Yarn ？</h1><p>直接的原因呢，就是因为 Hadoop1.0 中架构的缺陷，在 MapReduce 中，jobTracker 担负起了太多的责任了，接收任务是它，资源调度是它，监控 TaskTracker 运行情况还是它。这样实现的好处是比较简单，但相对的，就容易出现一些问题，比如常见的单点故障问题。</p>
<p>要解决这些问题，只能将 jobTracker 进行拆分，将其中部分功能拆解出来。彼时业内已经有了一部分的资源管理框架，比如 mesos，于是照着这个思路，就开发出了 Yarn。这里多说个冷知识，其实 Spark 早期是为了推广 mesos 而产生的，这也是它名字的由来，不过后来反正是 Spark 火起来了。</p>
<p>其实 Hadoop 能有今天这个地位，Yarn 可以说是功不可没。因为有了 Yarn ，更多计算框架可以接入到 Hdfs 中，而不单单是 MapReduce，到现在我们都知道，MapReduce 早已经被 Spark 等计算框架赶超，而 Hdfs 却依然屹立不倒。究其原因，正式因为 Yarn 的包容，使得其他计算框架能专注于计算性能的提升。Hdfs 可能不是最优秀的大数据存储系统，但却是应用最广泛的大数据存储系统，Yarn 功不可没。</p>
<h1 id="YARN：下一代-Hadoop-计算平台"><a href="#YARN：下一代-Hadoop-计算平台" class="headerlink" title="YARN：下一代 Hadoop 计算平台"></a>YARN：下一代 Hadoop 计算平台</h1><p>以下名称的改动有助于更好地了解 YARN 的设计：</p>
<ul>
<li>ResourceManager 代替集群管理器</li>
<li>ApplicationMaster 代替一个专用且短暂的 JobTracker</li>
<li>NodeManager 代替 TaskTracker</li>
<li>一个分布式应用程序代替一个 MapReduce 作业</li>
</ul>
<p>YARN 是下一代 Hadoop 计算平台，如下所示。</p>
<h2 id="YARN-架构"><a href="#YARN-架构" class="headerlink" title="YARN 架构"></a>YARN 架构</h2><p><img src="/2020/02/21/Yarn%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/image-20200221230620139.png" alt="image-20200221230620139"></p>
<p><img src="/2020/02/21/Yarn%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/image-20200221230631351.png" alt="image-20200221230631351"></p>
<p>假设用户采用与 MRv1 中相同的方式键入 <code>hadoop jar</code> 命令，将应用程序提交到 ResourceManager。ResourceManager 维护在集群上运行的应用程序列表，以及每个活动的 NodeManager 上的可用资源列表。ResourceManager 需要确定哪个应用程序接下来应该获得一部分集群资源。该决策受到许多限制，比如队列容量、ACL 和公平性。ResourceManager 使用一个可插拔的 Scheduler。Scheduler 仅执行调度；它管理谁在何时获取集群资源（以容器的形式），但不会对应用程序内的任务执行任何监视，所以它不会尝试重新启动失败的任务。</p>
<p>在 YARN 架构中，一个全局 ResourceManager 以主要后台进程的形式运行，它通常在专用机器上运行，在各种竞争的应用程序之间仲裁可用的集群资源。ResourceManager 会追踪集群中有多少可用的活动节点和资源，协调用户提交的哪些应用程序应该在何时获取这些资源。ResourceManager 是惟一拥有此信息的进程，所以它可通过某种共享的、安全的、多租户的方式制定分配（或者调度）决策（例如，依据应用程序优先级、队列容量、ACLs、数据位置等）。</p>
<p>在用户提交一个应用程序时，一个称为 ApplicationMaster 的轻量型进程实例会启动来协调应用程序内的所有任务的执行。这包括监视任务，重新启动失败的任务，推测性地运行缓慢的任务，以及计算应用程序计数器值的总和。这些职责以前分配给所有作业的单个 JobTracker。ApplicationMaster 和属于它的应用程序的任务，在受 NodeManager 控制的资源容器中运行。</p>
<p>NodeManager 是 TaskTracker 的一种更加普通和高效的版本。没有固定数量的 map 和 reduce slots，NodeManager 拥有许多动态创建的资源容器。容器的大小取决于它所包含的资源量，比如内存、CPU、磁盘和网络 IO。目前，仅支持内存和 CPU (YARN-3)。未来可使用 cgroups 来控制磁盘和网络 IO。一个节点上的容器数量，由配置参数与专用于从属后台进程和操作系统的资源以外的节点资源总量（比如总 CPU 数和总内存）共同决定。</p>
<p>有趣的是，ApplicationMaster 可在容器内运行任何类型的任务。例如，MapReduce ApplicationMaster 请求一个容器来启动 map 或 reduce 任务，而 Giraph ApplicationMaster 请求一个容器来运行 Giraph 任务。您还可以实现一个自定义的 ApplicationMaster 来运行特定的任务，进而发明出一种全新的分布式应用程序框架，改变大数据世界的格局。您可以查阅 Apache Twill，它旨在简化 YARN 之上的分布式应用程序的编写。</p>
<p>在 YARN 中，MapReduce 降级为一个分布式应用程序的一个角色（但仍是一个非常流行且有用的角色），现在称为 MRv2。MRv2 是经典 MapReduce 引擎（现在称为 MRv1）的重现，运行在 YARN 之上。</p>
<h2 id="Container"><a href="#Container" class="headerlink" title="Container"></a><strong>Container</strong></h2><p>容器（Container）这个东西是 Yarn 对资源做的一层抽象。就像我们平时开发过程中，经常需要对底层一些东西进行封装，只提供给上层一个调用接口一样，Yarn 对资源的管理也是用到了这种思想。</p>
<img src="/2020/02/21/Yarn%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/image-20200221230721971.png" alt="image-20200221230721971" style="zoom:80%;">

<p>如上所示，Yarn 将CPU核数，内存这些计算资源都封装成为一个个的容器（Container）。需要注意两点：</p>
<ul>
<li>容器由 NodeManager 启动和管理，并被它所监控。</li>
<li>容器被 ResourceManager 进行调度。</li>
</ul>
<p>NodeManager 和 ResourceManager 这两个组件会在下面讲到。</p>
<h2 id="三个主要组件"><a href="#三个主要组件" class="headerlink" title="三个主要组件"></a><strong>三个主要组件</strong></h2><p>再看最上面的图，我们能直观发现的两个主要的组件是 <strong>ResourceManager</strong> 和 <strong>NodeManager</strong> ，但其实还有一个 <strong>ApplicationMaster</strong> 在图中没有直观显示。我们分别来看这三个组件。</p>
<h3 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a><strong>ResourceManager</strong></h3><p>我们先来说说上图中最中央的那个 ResourceManager（RM）。从名字上我们就能知道这个组件是负责资源管理的，整个系统有且只有一个 RM ，来负责资源的调度。它也包含了两个主要的组件：资源调度器(Scheduler)以及应用管理器(ApplicationManager)。</p>
<ol>
<li>资源调度器(Scheduler)：从本质上来说，资源调度器就是一种策略，或者说一种算法。当 Client 提交一个任务的时候，它会根据所需要的资源以及当前集群的资源状况进行分配。注意，它只负责向应用程序分配资源，并不做监控以及应用程序的状态跟踪。</li>
<li>应用管理器(ApplicationManager)：同样，听名字就能大概知道它是干嘛的。应用管理器就是负责管理 Client 用户提交的应用。上面不是说到资源调度器（Scheduler）不对用户提交的程序监控嘛，其实啊，监控应用的工作正是由应用管理器（ApplicationManager）完成的。</li>
</ol>
<h3 id="ApplicationMaster"><a href="#ApplicationMaster" class="headerlink" title="ApplicationMaster"></a><strong>ApplicationMaster</strong></h3><p>每当 Client 提交一个 Application 时候，就会新建一个 ApplicationMaster 。由这个 ApplicationMaster 去与 ResourceManager 申请容器资源，获得资源后会将要运行的程序发送到容器上启动，然后进行分布式计算。</p>
<p>这里可能有些难以理解，为什么是把运行程序发送到容器上去运行？如果以传统的思路来看，是程序运行着不动，然后数据进进出出不停流转。但当数据量大的时候就没法这么玩了，因为海量数据移动成本太大，时间太长。但是中国有一句老话<strong>山不过来，我就过去。</strong>大数据分布式计算就是这种思想，既然大数据难以移动，那我就把容易移动的应用程序发布到各个节点进行计算呗，这就是大数据分布式计算的思路。</p>
<h3 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a><strong>NodeManager</strong></h3><p>NodeManager 是 ResourceManager 在每台机器的上代理，负责容器的管理，并监控他们的资源使用情况（cpu，内存，磁盘及网络等），以及向 ResourceManager/Scheduler 提供这些资源使用报告。</p>
<h2 id="提交一个-Application-到-Yarn-的流程"><a href="#提交一个-Application-到-Yarn-的流程" class="headerlink" title="提交一个 Application 到 Yarn 的流程"></a><strong>提交一个 Application 到 Yarn 的流程</strong></h2><img src="/2020/02/21/Yarn%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/image-20200221230834987.png" alt="image-20200221230834987" style="zoom: 80%;">

<p>这张图简单地标明了提交一个程序所经历的流程，接下来我们来具体说说每一步的过程。</p>
<ol>
<li>Client 向 Yarn 提交 Application，这里我们假设是一个 MapReduce 作业。</li>
<li>ResourceManager 向 NodeManager 通信，为该 Application 分配第一个容器。并在这个容器中运行这个应用程序对应的 ApplicationMaster。</li>
<li>ApplicationMaster 启动以后，对 作业（也就是 Application） 进行拆分，拆分 task 出来，这些 task 可以运行在一个或多个容器中。然后向 ResourceManager 申请要运行程序的容器，并定时向 ResourceManager 发送心跳。</li>
<li>申请到容器后，ApplicationMaster 会去和容器对应的 NodeManager 通信，而后将作业分发到对应的 NodeManager 中的容器去运行，这里会将拆分后的 MapReduce 进行分发，对应容器中运行的可能是 Map 任务，也可能是 Reduce 任务。</li>
<li>容器中运行的任务会向 ApplicationMaster 发送心跳，汇报自身情况。当程序运行完成后， ApplicationMaster 再向 ResourceManager 注销并释放容器资源。</li>
</ol>
<p>以上就是一个作业的大体运行流程。</p>
<h2 id="可运行任何分布式应用程序的集群"><a href="#可运行任何分布式应用程序的集群" class="headerlink" title="可运行任何分布式应用程序的集群"></a>可运行任何分布式应用程序的集群</h2><p>ResourceManager、NodeManager 和容器都不关心应用程序或任务的类型。所有特定于应用程序框架的代码都转移到它的 ApplicationMaster，以便任何分布式框架都可以受 YARN 支持 — 只要有人为它实现了相应的 ApplicationMaster。</p>
<p>得益于这个一般性的方法，Hadoop YARN 集群运行许多不同工作负载的梦想才得以实现。想像一下：您数据中心中的一个 Hadoop 集群可运行 MapReduce、Giraph、Storm、Spark、Tez/Impala、MPI 等。</p>
<p>单一集群方法明显提供了大量优势，其中包括：</p>
<ul>
<li>更高的集群利用率，一个框架未使用的资源可由另一个框架使用</li>
<li>更低的操作成本，因为只有一个 “包办一切的” 集群需要管理和调节</li>
<li>更少的数据移动，无需在 Hadoop YARN 与在不同机器集群上运行的系统之间移动数据</li>
</ul>
<p>管理单个集群还会得到一个更环保的数据处理解决方案。使用的数据中心空间更少，浪费的硅片更少，使用的电源更少，排放的碳更少，这只是因为我们在更小但更高效的 Hadoop 集群上运行同样的计算。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Yarn</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>V2Ray一键安装脚本</title>
    <url>/2020/02/21/V2Ray%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<p><a href="https://github.com/233boy/v2ray/wiki/V2Ray%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC" target="_blank" rel="noopener">V2Ray一键安装脚本</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bash &lt;(curl -s -L https://git.io/v2ray.sh)</span><br></pre></td></tr></table></figure>

 <a id="more"></a>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">重要：建议用Debian系统，其他系统像Centos死活不会成功！</span><br><span class="line">如putty连接不上，可替换成xshell，勾选代理模式就可以连接被墙IP了，有的老铁说putty和xshell都不懂怎么办，那你可以到你vps管理界面后台，通过自带网页ssh，只是命令你要手敲，总会有办法的😂</span><br><span class="line">对了，我用V2Ray全局，一直可以连接被墙ip，有条件朋友可以试试</span><br><span class="line"> </span><br><span class="line">注意注意：有的老铁到域名解析那步，输入域名说为什么超时，因为你的IP被墙了，肯定超时，这一步Ping一下只是确认你的DNS解析成功，只要输入域名后显示的是你的IP，说明就可以进入下一步安装V2Ray了，不要傻傻等很多为什么还是超时，超时就对了，直接跟着视频下一步就没问题了！！！</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">V2Ray进阶篇2：V2Ray+Websocket+TLS+Cloudflare拯救被墙的IP，简单易懂，欢迎订阅点赞！</span><br><span class="line">经广大网友反馈实践，申请免费域名时最好挂美国VPN全局，非美国VPN会提示技术错误等原因，其他地区VPN不保证能成功！！！</span><br><span class="line"> </span><br><span class="line">视频涉及的网址（大多要翻墙&#x2F;开全局VPN打开）：</span><br><span class="line">Vultr-VPS官网：https:&#x2F;&#x2F;www.vultr.com&#x2F;?ref&#x3D;7145378</span><br><span class="line">PUTTY下载：https:&#x2F;&#x2F;www.chiark.greenend.org.uk&#x2F;~s...</span><br><span class="line">VPS更改北京时间：https:&#x2F;&#x2F;blog.csdn.net&#x2F;zx711166&#x2F;articl...</span><br><span class="line">ping检测官网：http:&#x2F;&#x2F;ping.chinaz.com&#x2F;</span><br><span class="line">免费域名申请：https:&#x2F;&#x2F;www.freenom.com&#x2F;zh （尽量挂美国代理）</span><br><span class="line">Cloudflare官网:https:&#x2F;&#x2F;www.cloudflare.com&#x2F;</span><br><span class="line">V2Ray脚本地址：https:&#x2F;&#x2F;ppig.xyz&#x2F;post&#x2F;5&#x2F;</span><br><span class="line"> </span><br><span class="line">V2Ray Windows客户端图形化界面地址：https:&#x2F;&#x2F;github.com&#x2F;2dust&#x2F;v2rayN&#x2F;releases</span><br><span class="line">V2Ray安卓客户端：https:&#x2F;&#x2F;github.com&#x2F;2dust&#x2F;v2rayNG&#x2F;releases</span><br><span class="line">V2Ray mac客户端：https:&#x2F;&#x2F;github.com&#x2F;Cenmrev&#x2F;V2RayX&#x2F;releases</span><br><span class="line">V2Ray苹果IOS客户a端安装：https:&#x2F;&#x2F;youtu.be&#x2F;jxBkhHGzWts</span><br><span class="line"> </span><br><span class="line">相关推荐</span><br><span class="line">V2Ray高级进阶篇1：Websocket+TLS+V2Ray的搭建:https:&#x2F;&#x2F;youtu.be&#x2F;AlJ4EQg_zQQ</span><br><span class="line"> </span><br><span class="line">欢迎订阅、点赞、加关注</span><br><span class="line">任何不明白的请留言！</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>外面的世界</category>
      </categories>
      <tags>
        <tag>V2Ray</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Jupyter服务搭建</title>
    <url>/2020/02/21/Python-jupyter-%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h2 id="生成一个-notebook-配置文件"><a href="#生成一个-notebook-配置文件" class="headerlink" title="生成一个 notebook 配置文件"></a>生成一个 notebook 配置文件</h2><p>默认情况下，配置文件 <code>~/.jupyter/jupyter_notebook_config.py</code>并不存在，需要自行创建。使用下列命令生成配置文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure>
<p>执行成功后，会出现下面的信息：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Writing default config to: /root/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h2 id="生成密码"><a href="#生成密码" class="headerlink" title="生成密码"></a>生成密码</h2><h3 id="自动生成"><a href="#自动生成" class="headerlink" title="自动生成"></a>自动生成</h3><p>从 jupyter notebook 5.0 版本开始，提供了一个命令来设置密码：<code>jupyter notebook password</code>，生成的密码存储在 <code>jupyter_notebook_config.json</code>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> jupyter notebook password</span></span><br><span class="line">Enter password:  ****</span><br><span class="line">Verify password: ****</span><br><span class="line">[NotebookPasswordApp] Wrote hashed password to /Users/you/.jupyter/jupyter_notebook_config.json</span><br></pre></td></tr></table></figure>
<h3 id="手动生成"><a href="#手动生成" class="headerlink" title="手动生成"></a>手动生成</h3><p>打开 ipython 执行下面内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">In [<span class="number">2</span>]: passwd()</span><br><span class="line">Enter password:</span><br><span class="line">Verify password:</span><br><span class="line">Out[<span class="number">2</span>]: <span class="string">'sha1:295dc2c9f8ba:1dd06dd1b37b6feffe6d1adeef0c02186f645d9d'</span></span><br></pre></td></tr></table></figure>
<p><code>sha1:295dc2c9f8ba:1dd06dd1b37b6feffe6d1adeef0c02186f645d9d</code>这一串就是要在 <code>jupyter_notebook_config.py</code>添加的密码。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c.NotebookApp.password &#x3D; u&#39;sha1:295dc2c9f8ba:1dd06dd1b37b6feffe6d1adeef0c02186f645d9d&#39;</span><br></pre></td></tr></table></figure>

<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>在 <code>jupyter_notebook_config.py</code> 中找到下面的行，取消注释并修改。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">c.NotebookApp.ip=<span class="string">'*'</span></span><br><span class="line">c.NotebookApp.password = <span class="string">u'sha1:295dc2c9f8ba:1dd06dd1b37b6feffe6d1adeef0c02186f645d9d'</span></span><br><span class="line">c.NotebookApp.open_browser = <span class="literal">False</span></span><br><span class="line">c.NotebookApp.port = <span class="number">9090</span></span><br></pre></td></tr></table></figure>

<h2 id="运行jupyter服务"><a href="#运行jupyter服务" class="headerlink" title="运行jupyter服务"></a>运行jupyter服务</h2><p>以上设置完以后就可以在服务器上启动 <code>jupyter-lab</code>, root 用户使用 <code>jupyter-lab --allow-root</code>。打开 <code>IP:指定的端口</code>, 输入密码就可以访问了。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 后台执行</span></span><br><span class="line">nohup jupyter-lab --allow-root &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache Ambari-2.7.4.0 Centos7离线安装</title>
    <url>/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><h2 id="Ambari"><a href="#Ambari" class="headerlink" title="Ambari"></a>Ambari</h2><ul>
<li>Ambari 跟 Hadoop 等开源软件一样，也是 Apache Software Foundation 中的一个项目，并且是顶级项目。就 Ambari 的作用来说，就是创建、管理、监视 Hadoop 的集群，但是这里的 Hadoop 指的是 Hadoop 整个生态圈（例如 Hive，Hbase，Sqoop，Zookeeper 等）， 而并不仅是特指 Hadoop。用一句话来说，Ambari 就是为了让 Hadoop 以及相关的大数据软件更容易使用的一个工具。</li>
<li>Ambari 自身也是一个分布式架构的软件，主要由两部分组成：Ambari Server 和 Ambari Agent。简单来说，用户通过 Ambari Server 通知 Ambari Agent 安装对应的软件；Agent 会定时地发送各个机器每个软件模块的状态给 Ambari Server，最终这些状态信息会呈现在 Ambari 的 GUI，方便用户了解到集群的各种状态，并进行相应的维护。</li>
</ul>
<a id="more"></a>

<h2 id="HDP"><a href="#HDP" class="headerlink" title="HDP"></a>HDP</h2><ul>
<li>HDP是hortonworks的软件栈，里面包含了hadoop生态系统的所有软件项目，比如HBase,Zookeeper,Hive,Pig等等。</li>
</ul>
<h2 id="HDP-UTILS"><a href="#HDP-UTILS" class="headerlink" title="HDP-UTILS"></a>HDP-UTILS</h2><ul>
<li>HDP-UTILS是工具类库。</li>
</ul>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><h2 id="Ambari、HDP版本介绍"><a href="#Ambari、HDP版本介绍" class="headerlink" title="Ambari、HDP版本介绍"></a>Ambari、HDP版本介绍</h2><ul>
<li>Ambari 2.7.4.0支持HDP-3.1.4使用以下URL确定对每个产品版本的支持<br><a href="https://supportmatrix.hortonworks.com/" target="_blank" rel="noopener">https://supportmatrix.hortonworks.com/</a>，以及下载报告</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220201704962.png" alt="image-20200220201704962"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220201743769.png" alt="image-20200220201743769"></p>
<h2 id="搭建环境准备"><a href="#搭建环境准备" class="headerlink" title="搭建环境准备"></a>搭建环境准备</h2><h3 id="软件要求"><a href="#软件要求" class="headerlink" title="软件要求"></a>软件要求</h3><table>
<thead>
<tr>
<th align="center">组件</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">操作系统</td>
<td align="center">Centos 7.7</td>
</tr>
<tr>
<td align="center">Ambari</td>
<td align="center">2.7.4.0</td>
</tr>
<tr>
<td align="center">HDP</td>
<td align="center">3.1.4.0</td>
</tr>
<tr>
<td align="center">HDP-GPL</td>
<td align="center">3.1.4.0</td>
</tr>
<tr>
<td align="center">HDP-UTILS</td>
<td align="center">1.1.0.22</td>
</tr>
<tr>
<td align="center">Mysql</td>
<td align="center">5.7</td>
</tr>
<tr>
<td align="center">JDK8</td>
<td align="center">jdk1.8.0_221</td>
</tr>
<tr>
<td align="center">scala</td>
<td align="center">2.11.12</td>
</tr>
<tr>
<td align="center">X86</td>
<td align="center">X86-64</td>
</tr>
</tbody></table>
<h3 id="软件下载"><a href="#软件下载" class="headerlink" title="软件下载"></a>软件下载</h3><ul>
<li>Centos 7清华镜像 <a href="https://mirrors.tuna.tsinghua.edu.cn/centos/7/isos/x86_64/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/centos/7/isos/x86_64/</a></li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220202924124.png" alt="image-20200220202924124"></p>
<ul>
<li>Ambari 2.7.4.0安装包下载地址：<a href="https://docs.cloudera.com/HDPDocuments/Ambari-2.7.4.0/bk_ambari-installation/content/ambari_repositories.html" target="_blank" rel="noopener">https://docs.cloudera.com/HDPDocuments/Ambari-2.7.4.0/bk_ambari-installation/content/ambari_repositories.html</a></li>
<li>HDP 3.1.4.0、HDP-GPL-3.1.4.0 和 HDP-UTILS 1.1.0.22安装包下载地址：<a href="https://docs.cloudera.com/HDPDocuments/Ambari-2.7.4.0/bk_ambari-installation/content/hdp_314_repositories.html" target="_blank" rel="noopener">https://docs.cloudera.com/HDPDocuments/Ambari-2.7.4.0/bk_ambari-installation/content/hdp_314_repositories.html</a></li>
<li>MySQL 5.7</li>
<li>OracleJDK8 1.8.0_221下载地址：<a href="https://www.oracle.com/technetwork/cn/java/javase/downloads/java-archive-javase8-2177648-zhs.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/cn/java/javase/downloads/java-archive-javase8-2177648-zhs.html</a></li>
</ul>
<h2 id="集群节点规划准备"><a href="#集群节点规划准备" class="headerlink" title="集群节点规划准备"></a>集群节点规划准备</h2><table>
<thead>
<tr>
<th align="center">Hostname</th>
<th align="center">IP</th>
<th align="center">Functions</th>
<th align="center">CPU</th>
<th align="center">内存</th>
<th align="center">硬盘</th>
</tr>
</thead>
<tbody><tr>
<td align="center">yunm.hdp</td>
<td align="center">192.168.2.77</td>
<td align="center">Ambari/HDP packages</td>
<td align="center">4C</td>
<td align="center">8G</td>
<td align="center">200G</td>
</tr>
<tr>
<td align="center">nd-00.hdp</td>
<td align="center">192.168.2.100</td>
<td align="center">Ambari Server</td>
<td align="center">4C</td>
<td align="center">8G</td>
<td align="center">200G</td>
</tr>
<tr>
<td align="center">nd-01.hdp</td>
<td align="center">192.168.2.101</td>
<td align="center">Compute node</td>
<td align="center">4C</td>
<td align="center">8G</td>
<td align="center">200G</td>
</tr>
<tr>
<td align="center">nd-02.hdp</td>
<td align="center">192.168.2.102</td>
<td align="center">Compute node</td>
<td align="center">4C</td>
<td align="center">8G</td>
<td align="center">200G</td>
</tr>
</tbody></table>
<h1 id="搭建虚拟机"><a href="#搭建虚拟机" class="headerlink" title="搭建虚拟机"></a>搭建虚拟机</h1><ul>
<li>搭建yum.hdp虚拟机，然后完成克隆，虚拟机搭建完毕。</li>
</ul>
<h2 id="搭建yum-hdp虚拟机"><a href="#搭建yum-hdp虚拟机" class="headerlink" title="搭建yum.hdp虚拟机"></a>搭建yum.hdp虚拟机</h2><p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203046966.png" alt="image-20200220203046966"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203059759.png" alt="image-20200220203059759"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203110491.png" alt="image-20200220203110491"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203122553.png" alt="image-20200220203122553"></p>
<h2 id="配置yum-hdp虚拟机"><a href="#配置yum-hdp虚拟机" class="headerlink" title="配置yum.hdp虚拟机"></a>配置yum.hdp虚拟机</h2><h3 id="配置静态IP"><a href="#配置静态IP" class="headerlink" title="配置静态IP"></a>配置静态IP</h3><ul>
<li>打开文件：vi /etc/sysconfig/network-scripts/ifcfg-ens192</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203240722.png" alt="image-20200220203240722"></p>
<ul>
<li>重启：service network start</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203311168.png" alt="image-20200220203311168"></p>
<ul>
<li>查看：ifconfig【安装命令：yum -y install net-tools】</li>
</ul>
<h3 id="防火墙设置"><a href="#防火墙设置" class="headerlink" title="防火墙设置"></a>防火墙设置</h3><ul>
<li>查看防火墙的状态：systemctl status firewalld.service</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203726175.png" alt="image-20200220203726175"></p>
<ul>
<li>关闭防火墙：systemctl stop firewalld.service</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203751452.png" alt="image-20200220203751452"></p>
<ul>
<li>设置开机不启动：systemctl disable firewalld.service</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203847349.png" alt="image-20200220203847349"></p>
<ul>
<li>查看防火墙服务是否设置开机启动：systemctl is-enabled firewalld.service</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220203917637.png" alt="image-20200220203917637"></p>
<h3 id="设置hostname"><a href="#设置hostname" class="headerlink" title="设置hostname"></a>设置hostname</h3><ul>
<li>设置hosts：vi /etc/hosts</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204121994.png" alt="image-20200220204121994"></p>
<ul>
<li>修改：vi /etc/sysconfig/network</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204157475.png" alt="image-20200220204157475"></p>
<ul>
<li>执行：hostnamectl set-hostname yum.hdp</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204208509.png" alt="image-20200220204208509"></p>
<h3 id="安装时间同步服务（ntp）"><a href="#安装时间同步服务（ntp）" class="headerlink" title="安装时间同步服务（ntp）"></a>安装时间同步服务（ntp）</h3><ul>
<li><p>安装：yum install -y ntp</p>
</li>
<li><p>启动并查看状态：</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start ntpd.service</span><br><span class="line">systemctl status ntpd.service</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204341095.png" alt="image-20200220204341095"></p>
<ul>
<li>设置开机自启：systemctl enable ntpd.service</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204349178.png" alt="image-20200220204349178"></p>
<h3 id="安装并配置JDK"><a href="#安装并配置JDK" class="headerlink" title="安装并配置JDK"></a>安装并配置JDK</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar –xvzf jdk-8u221-linux-x64.tar.gz</span><br><span class="line"> </span><br><span class="line">vi /etc/profile</span><br><span class="line">export JAVA_HOME=/opt/jdk1.8.0_221</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">source /etc/profile</span><br><span class="line"> </span><br><span class="line">java -version</span><br></pre></td></tr></table></figure>

<h3 id="安装并配置scala"><a href="#安装并配置scala" class="headerlink" title="安装并配置scala"></a>安装并配置scala</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar –xvzf scala-2.11.12.tgz</span><br><span class="line"> </span><br><span class="line">vi /etc/profile</span><br><span class="line">export SCALA_HOME=/opt/scala-2.11.12</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br><span class="line">source /etc/profile</span><br><span class="line"> </span><br><span class="line">scala -version</span><br></pre></td></tr></table></figure>

<h3 id="关闭Selinux和THP（如果不关闭THP，Hadoop的系统CPU使用率很高）"><a href="#关闭Selinux和THP（如果不关闭THP，Hadoop的系统CPU使用率很高）" class="headerlink" title="关闭Selinux和THP（如果不关闭THP，Hadoop的系统CPU使用率很高）"></a>关闭Selinux和THP（如果不关闭THP，Hadoop的系统CPU使用率很高）</h3><ul>
<li>查看状态：sestatus</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204627146.png" alt="image-20200220204627146"></p>
<ul>
<li>关闭：vim /etc/sysconfig/selinux</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204649551.png" alt="image-20200220204649551"></p>
<ul>
<li>如果出现下述结果说明启动了THP</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204703098.png" alt="image-20200220204703098"></p>
<ul>
<li>永久关闭：vim /etc/rc.d/rc.local</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">if test -f /sys/kernel/mm/transparent_hugepage/enabled; then</span><br><span class="line">        echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">fi</span><br><span class="line">if test -f /sys/kernel/mm/transparent_hugepage/defrag; then</span><br><span class="line">        echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204715380.png" alt="image-20200220204715380"></p>
<ul>
<li>保存退出，然后赋予rc.local文件执行权限：chmod +x /etc/rc.d/rc.local</li>
<li>重启：reboot</li>
</ul>
<h3 id="最大打开文件要求"><a href="#最大打开文件要求" class="headerlink" title="最大打开文件要求"></a>最大打开文件要求</h3><ul>
<li>建议的最大打开文件描述符数为10000或更多。</li>
<li>修改配置文件 vi /etc/security/limits.conf</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">*       soft    nofile  65535</span><br><span class="line">*       hard    nofile  65535</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204746159.png" alt="image-20200220204746159"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204753727.png" alt="image-20200220204753727"></p>
<h2 id="克隆yum-hdp虚拟机"><a href="#克隆yum-hdp虚拟机" class="headerlink" title="克隆yum.hdp虚拟机"></a>克隆yum.hdp虚拟机</h2><h3 id="开始克隆"><a href="#开始克隆" class="headerlink" title="开始克隆"></a>开始克隆</h3><ul>
<li>克隆另外三台虚拟机：yum.hdp、nd-00.hdp、nd-01.hdp、nd-02.hdp</li>
</ul>
<h3 id="修改参数"><a href="#修改参数" class="headerlink" title="修改参数"></a>修改参数</h3><ul>
<li>启动nd-00.hdp，nd-01.hdp，nd-02.hdp虚拟机，并修改虚拟机的IP地址</li>
<li>vi /etc/sysconfig/network-scripts/ifcfg-ens192</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204933844.png" alt="image-20200220204933844"></p>
<ul>
<li>重启network：service network start</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220204946224.png" alt="image-20200220204946224"></p>
<ul>
<li>修改虚拟机hostname：vi /etc/sysconfig/network</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205002542.png" alt="image-20200220205002542"></p>
<ul>
<li>修改虚拟机hostname：hostnamectl set-hostname nd-00.hdp</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205015834.png" alt="image-20200220205015834"></p>
<ul>
<li>关闭虚拟机，并重新分配内存</li>
</ul>
<h3 id="在nd-00-hdp虚拟机上安装mysql"><a href="#在nd-00-hdp虚拟机上安装mysql" class="headerlink" title="在nd-00.hdp虚拟机上安装mysql"></a>在nd-00.hdp虚拟机上安装mysql</h3><ul>
<li><p>下载并安装mysql【yum install wget】</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm</span><br><span class="line">yum -y install mysql57-community-release-el7-10.noarch.rpm</span><br><span class="line">yum -y install mysql-community-server</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动mysql并设置开机自启</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start mysqld.service    # 启动mysql</span><br><span class="line">systemctl status mysqld.service  # 查看mysql状态</span><br><span class="line">systemctl stop mysqld.service   # 关闭mysql</span><br><span class="line">systemctl enable mysqld.service   # 开机自启</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205154210.png" alt="image-20200220205154210"></p>
<ul>
<li>此时MySQL已经开始正常运行，不过要想进入MySQL还得先找出此时root用户的密码，通过如下命令可以在日志文件中找出密码：cat /var/log/mysqld.log | grep pass</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205203712.png" alt="image-20200220205203712"></p>
<ul>
<li>输入初始密码，此时不能做任何事情，因为MySQL默认必须修改密码之后才能操作数据库</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set global validate_password_policy=0;</span><br><span class="line">set global validate_password_length=1;</span><br><span class="line">ALTER USER 'root'@'localhost' IDENTIFIED BY 'root123';</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205214164.png" alt="image-20200220205214164"></p>
<ul>
<li>但此时还有一个问题，就是因为安装了Yum Repository，以后每次yum操作都会自动更新，需要把这个卸载掉</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y remove mysql57-community-release-el7-10.noarch</span><br></pre></td></tr></table></figure>

<ul>
<li>配置mysql编码，字符格式：vim /etc/my.cnf</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">在[mysqld]下添加</span><br><span class="line">collation_server=utf8_general_ci</span><br><span class="line">character_set_server=utf8</span><br><span class="line">default-storage-engine=INNODB</span><br><span class="line">在[client]下添加（如果没有[client]，则创建）</span><br><span class="line">default_character-set=utf8</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205230941.png" alt="image-20200220205230941"></p>
<ul>
<li>重启mysql服务：systemctl restart mysqld.service</li>
<li>查看字符集： show variables like ‘character_set_%’ ;</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205239792.png" alt="image-20200220205239792"></p>
<h3 id="在mysql数据库创建相应的用户和DB"><a href="#在mysql数据库创建相应的用户和DB" class="headerlink" title="在mysql数据库创建相应的用户和DB"></a>在mysql数据库创建相应的用户和DB</h3><ul>
<li>创建ambari数据库及数据库的用户名和密码</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set global validate_password_policy=0;</span><br><span class="line">set global validate_password_length=1;</span><br><span class="line">create database ambari character set utf8;</span><br><span class="line">CREATE USER 'ambari'@'%'IDENTIFIED BY 'Ambari123';</span><br><span class="line">GRANT ALL PRIVILEGES ON ambari.* TO 'ambari'@'%';</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205516910.png" alt="image-20200220205516910"></p>
<ul>
<li>创建hive数据库及hive库的用户名和密码</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create database hive character set utf8;</span><br><span class="line">CREATE USER 'hive'@'%'IDENTIFIED BY 'Hive123';</span><br><span class="line">GRANT ALL PRIVILEGES ON hive.* TO 'hive'@'%';</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205531051.png" alt="image-20200220205531051"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205541563.png" alt="image-20200220205541563"></p>
<ul>
<li>下载mysql-connection-java：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install mysql-connector-java</span><br></pre></td></tr></table></figure>

<ul>
<li>查看下载后的jar包，看目录中是否有mysql-connector-java:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /usr/share/java/mysql-connector-java.jar</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205552949.png" alt="image-20200220205552949"></p>
<h3 id="免密登录"><a href="#免密登录" class="headerlink" title="免密登录"></a>免密登录</h3><ul>
<li>配置本地hosts文件</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205653230.png" alt="image-20200220205653230"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205708704.png" alt="image-20200220205708704"></p>
<ul>
<li>nd-00.hdp ⇒ 00，01，02的免密登录：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@nd-00 ~]# ssh-keygen -t rsa        # 一路回车</span><br><span class="line">[root@nd-00 ~]# ssh-copy-id nd-00.hdp    # 输入密码</span><br><span class="line">[root@nd-00 ~]# ssh-copy-id nd-01.hdp    # 输入密码</span><br><span class="line">[root@nd-00 ~]# ssh-copy-id nd-02.hdp    # 输入密码</span><br></pre></td></tr></table></figure>

<ul>
<li>nd-01.hdp ⇒ 01，02的免密登录：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@nd-01 ~]# ssh-keygen -t rsa        # 一路回车</span><br><span class="line">[root@nd-01 ~]# ssh-copy-id nd-01.hdp    # 输入密码</span><br><span class="line">[root@nd-01 ~]# ssh-copy-id nd-02.hdp    # 输入密码</span><br></pre></td></tr></table></figure>

<h1 id="在yum-hdp上安装Ambari"><a href="#在yum-hdp上安装Ambari" class="headerlink" title="在yum.hdp上安装Ambari"></a>在yum.hdp上安装Ambari</h1><h2 id="安装yum相关工具"><a href="#安装yum相关工具" class="headerlink" title="安装yum相关工具"></a>安装yum相关工具</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@yum ~]# yum install yum-utils -y</span><br><span class="line">[root@yum ~]# yum repolist</span><br><span class="line">[root@yum ~]# yum install createrepo -y</span><br></pre></td></tr></table></figure>

<h2 id="安装Apache-httpd"><a href="#安装Apache-httpd" class="headerlink" title="安装Apache httpd"></a>安装Apache httpd</h2><ul>
<li>上传下载文件hdp-3.1.4（借助xftp工具）</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205840641.png" alt="image-20200220205840641"></p>
<ul>
<li>使用yum在线安装httpd</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install httpd -y</span><br></pre></td></tr></table></figure>

<ul>
<li>启动httpd服务：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start httpd        # 启动httpd</span><br><span class="line">systemctl status httpd        # 查看httpd状态</span><br><span class="line">systemctl enable httpd        # 设置httpd开机自启</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205853444.png" alt="image-20200220205853444"></p>
<ul>
<li>默认端口80，浏览器输入：<a href="http://yum.hdp" target="_blank" rel="noopener">http://yum.hdp</a></li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205906904.png" alt="image-20200220205906904"></p>
<ul>
<li>httpd 会生成 /var/www/html目录（相当于Tomcat的webapps目录），进入到/var/www/html目录下，创建ambari和hdp目录，用来存放安装文件。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /var/www/html/ambari</span><br><span class="line">mkdir /var/www/html/hdp</span><br><span class="line">mkdir /var/www/html/hdp/HDP-UTILS-1.1.0.22</span><br><span class="line">mkdir /var/www/html/hdp/HDP-GPL-3.1.4.0</span><br><span class="line">tar -zxvf ambari-2.7.4.0-centos7.tar.gz -C /var/www/html/ambari/</span><br><span class="line">tar -zxvf HDP-3.1.4.0-centos7-rpm.tar.gz -C /var/www/html/hdp/</span><br><span class="line">tar -zxvf HDP-UTILS-1.1.0.22-centos7.tar.gz -C /var/www/html/hdp/HDP-UTILS-1.1.0.22/</span><br><span class="line">tar -zxvf HDP-GPL-3.1.4.0-centos7-gpl.tar.gz -C /var/www/html/hdp/HDP-GPL-3.1.4.0/</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205924855.png" alt="image-20200220205924855"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220205934705.png" alt="image-20200220205934705"></p>
<h2 id="配置本地-Repo"><a href="#配置本地-Repo" class="headerlink" title="配置本地 Repo"></a>配置本地 Repo</h2><h3 id="配置Ambari"><a href="#配置Ambari" class="headerlink" title="配置Ambari"></a>配置Ambari</h3><ul>
<li>修改配置文件：ambari.repo</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">VERSION_NUMBER=2.7.4.0-118</span></span><br><span class="line">[ambari-2.7.4.0]</span><br><span class="line"><span class="meta">#</span><span class="bash">json.url = http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json</span></span><br><span class="line">name=ambari Version - ambari-2.7.4.0</span><br><span class="line">baseurl=http://yum.hdp/ambari/ambari/centos7/2.7.4.0-118</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://yum.hdp/ambari/ambari/centos7/2.7.4.0-118/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br></pre></td></tr></table></figure>

<ul>
<li>配置HDP、HDP-UTILS、HDP-GPL</li>
<li>修改配置文件：hdp.repo</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">VERSION_NUMBER=3.1.4.0-315</span></span><br><span class="line">[HDP-3.1.4.0]</span><br><span class="line">name=HDP Version - HDP-3.1.4.0</span><br><span class="line">baseurl=http://yum.hdp/hdp/HDP/centos7</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://yum.hdp/hdp/HDP/centos7/3.1.4.0-315/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br><span class="line"></span><br><span class="line">[HDP-UTILS-1.1.0.22]</span><br><span class="line">name=HDP-UTILS Version - HDP-UTILS-1.1.0.22</span><br><span class="line">baseurl=http://yum.hdp/hdp/HDP-UTILS-1.1.0.22</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://yum.hdp/hdp/HDP-UTILS-1.1.0.22/HDP-UTILS/centos7/1.1.0.22/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br></pre></td></tr></table></figure>

<ul>
<li>修改配置文件：hdp.gpl.repo</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">VERSION_NUMBER=3.1.4.0-315</span></span><br><span class="line">[HDP-GPL-3.1.4.0]</span><br><span class="line">name=HDP-GPL Version - HDP-GPL-3.1.4.0</span><br><span class="line">baseurl=http://yum.hdp/hdp/HDP-GPL-3.1.4.0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://yum.hdp/hdp/HDP-GPL-3.1.4.0/HDP-GPL/centos7/3.1.4.0-315/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br></pre></td></tr></table></figure>

<h3 id="分发ambari-repo和hdp-repo、hdp-gpl-repo"><a href="#分发ambari-repo和hdp-repo、hdp-gpl-repo" class="headerlink" title="分发ambari.repo和hdp.repo、hdp.gpl.repo"></a>分发ambari.repo和hdp.repo、hdp.gpl.repo</h3><ul>
<li>repo文件放到/etc/yum.repos.d</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220210120836.png" alt="image-20200220210120836"></p>
<ul>
<li>把repo文件分发到各个节点的相同目录下</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp ambari.repo hdp.repo hdp.gpl.repo nd-00.hdp:$PWD</span><br><span class="line">scp ambari.repo hdp.repo hdp.gpl.repo nd-01.hdp:$PWD</span><br><span class="line">scp ambari.repo hdp.repo hdp.gpl.repo nd-02.hdp:$PWD</span><br></pre></td></tr></table></figure>

<h3 id="生成本地源"><a href="#生成本地源" class="headerlink" title="生成本地源"></a>生成本地源</h3><ul>
<li>使用createrepo命令，创建yum本地源（软件仓库），即为存放本地特定位置的众多rpm包建立索引，描述各包所需依赖信息，并形成元数据。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">createrepo /var/www/html/hdp/HDP/centos7/</span><br><span class="line">createrepo /var/www/html/hdp/HDP-UTILS-1.1.0.22/</span><br><span class="line">createrepo /var/www/html/hdp/HDP-GPL-3.1.4.0/</span><br><span class="line">createrepo /var/www/html/ambari/ambari/centos7/2.7.4.0-118/</span><br></pre></td></tr></table></figure>

<h1 id="安装Ambari-Server"><a href="#安装Ambari-Server" class="headerlink" title="安装Ambari-Server"></a>安装Ambari-Server</h1><h2 id="nd-00-hdp-节点安装"><a href="#nd-00-hdp-节点安装" class="headerlink" title="nd-00.hdp 节点安装"></a>nd-00.hdp 节点安装</h2><ul>
<li>安装ambari-server</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install ambari-server</span><br><span class="line">ambari-server setup</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(base) -bash-4.2# ambari-server setup</span><br><span class="line">Using python  /usr/bin/python</span><br><span class="line">Setup ambari-server</span><br><span class="line">Checking SELinux...</span><br><span class="line">SELinux status is 'disabled'</span><br><span class="line">Customize user account for ambari-server daemon [y/n] (n)? y</span><br><span class="line">Enter user account for ambari-server daemon (root):root</span><br><span class="line">Adjusting ambari-server permissions and ownership...</span><br><span class="line">Checking firewall status...</span><br><span class="line">Checking JDK...</span><br><span class="line">[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8</span><br><span class="line">[2] Custom JDK</span><br><span class="line">==============================================================================</span><br><span class="line">Enter choice (1): 2</span><br><span class="line">WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.</span><br><span class="line">WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.</span><br><span class="line">Path to JAVA_HOME: /opt/jdk1.8.0_221</span><br><span class="line">Validating JDK on Ambari Server...done.</span><br><span class="line">Check JDK version for Ambari Server...</span><br><span class="line">JDK version found: 8</span><br><span class="line">Minimum JDK version is 8 for Ambari. Skipping to setup different JDK for Ambari Server.</span><br><span class="line">Checking GPL software agreement...</span><br><span class="line">GPL License for LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html</span><br><span class="line">Enable Ambari Server to download and install GPL Licensed LZO packages [y/n] (n)? y</span><br><span class="line">Completing setup...</span><br><span class="line">Configuring database...</span><br><span class="line">Enter advanced database configuration [y/n] (n)? y</span><br><span class="line">Configuring database...</span><br><span class="line">==============================================================================</span><br><span class="line">Choose one of the following options:</span><br><span class="line">[1] - PostgreSQL (Embedded)</span><br><span class="line">[2] - Oracle</span><br><span class="line">[3] - MySQL / MariaDB</span><br><span class="line">[4] - PostgreSQL</span><br><span class="line">[5] - Microsoft SQL Server (Tech Preview)</span><br><span class="line">[6] - SQL Anywhere</span><br><span class="line">[7] - BDB</span><br><span class="line">==============================================================================</span><br><span class="line">Enter choice (1): 3</span><br><span class="line">Hostname (localhost): nd-00</span><br><span class="line">Port (3306): 3306</span><br><span class="line">Database name (ambari): </span><br><span class="line">Username (ambari): </span><br><span class="line">Enter Database Password (bigdata):     #密码不显示：Ambari123</span><br><span class="line">Re-enter password: </span><br><span class="line">Configuring ambari database...</span><br><span class="line">Should ambari use existing default jdbc /usr/share/java/mysql-connector-java.jar [y/n] (y)? y</span><br><span class="line">Configuring remote database connection properties...</span><br><span class="line">WARNING: Before starting Ambari Server, you must run the following DDL directly from the database shell to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql</span><br><span class="line">Proceed with configuring remote database connection properties [y/n] (y)? y</span><br><span class="line">Extracting system views...</span><br><span class="line">ambari-admin-2.7.4.0.118.jar</span><br><span class="line">....</span><br><span class="line">Ambari repo file contains latest json url http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json, updating stacks repoinfos with it...</span><br><span class="line">Adjusting ambari-server permissions and ownership...</span><br><span class="line">Ambari Server 'setup' completed successfully.</span><br><span class="line">(base) -bash-4.2#</span><br></pre></td></tr></table></figure>

<ul>
<li>使用root登录，设置允许远程登录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root -p</span><br><span class="line">set global validate_password_policy=0;</span><br><span class="line">set global validate_password_length=1;</span><br><span class="line">GRANT ALL PRIVILEGES ON ambari.* TO 'ambari'@'localhost' IDENTIFIED BY 'Ambari123';</span><br><span class="line">GRANT ALL PRIVILEGES ON ambari.* TO 'ambari'@'%' IDENTIFIED BY 'Ambari123';</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<ul>
<li>使用ambari登录</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220210351496.png" alt="image-20200220210351496"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> <span class="built_in">source</span> /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行完，查看有无报错信息，并查看数据表</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> show tables;</span></span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220210403897.png" alt="image-20200220210403897"></p>
<h2 id="启动Ambari-Server"><a href="#启动Ambari-Server" class="headerlink" title="启动Ambari-Server"></a>启动Ambari-Server</h2><ul>
<li>如果启动失败，关闭服务【ambari-server stop】，重新启动</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(base) -bash-4.2# ambari-server start</span><br><span class="line">Using python  /usr/bin/python</span><br><span class="line">Starting ambari-server</span><br><span class="line">Ambari Server running with administrator privileges.</span><br><span class="line">Organizing resource files at /var/lib/ambari-server/resources...</span><br><span class="line">Ambari database consistency check started...</span><br><span class="line">Server PID at: /var/run/ambari-server/ambari-server.pid</span><br><span class="line">Server out at: /var/log/ambari-server/ambari-server.out</span><br><span class="line">Server log at: /var/log/ambari-server/ambari-server.log</span><br><span class="line">Waiting for server start................................</span><br><span class="line">Server started listening on 8080</span><br><span class="line"></span><br><span class="line">DB configs consistency check: no errors and warnings were found.</span><br><span class="line">Ambari Server 'start' completed successfully.</span><br></pre></td></tr></table></figure>

<h2 id="安装Agent"><a href="#安装Agent" class="headerlink" title="安装Agent"></a>安装Agent</h2><ul>
<li>nd-00/01/02.hdp 所有节点安装ambari-agent</li>
</ul>
<p><code>yum -y install ambari-agent</code></p>
<h2 id="访问Ambari-web页面"><a href="#访问Ambari-web页面" class="headerlink" title="访问Ambari web页面"></a>访问Ambari web页面</h2><p>默认端口8080，Username：admin；Password：admin；<a href="http://192.168.121.100:8080" target="_blank" rel="noopener">http://192.168.121.100:8080</a></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220210612837.png" alt="image-20200220210612837"></p>
<h1 id="开始安装集群"><a href="#开始安装集群" class="headerlink" title="开始安装集群"></a>开始安装集群</h1><ul>
<li>配置集群名称</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211102777.png" alt="image-20200220211102777"></p>
<ul>
<li>选择版本</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211115145.png" alt="image-20200220211115145"></p>
<ul>
<li>配置节点、密钥</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211127892.png" alt="image-20200220211127892"></p>
<ul>
<li>主机确认</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211139211.png" alt="image-20200220211139211"></p>
<ul>
<li>选择大数据组件</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211148792.png" alt="image-20200220211148792"></p>
<ul>
<li>节点分配</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211157937.png" alt="image-20200220211157937"></p>
<ul>
<li>分配从属和客户端</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211206645.png" alt="image-20200220211206645"></p>
<ul>
<li>定制服务</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211215821.png" alt="image-20200220211215821"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211224207.png" alt="image-20200220211224207"></p>
<p><code>ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar</code></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211233909.png" alt="image-20200220211233909"></p>
<ul>
<li>集群整体概况，点击部署</li>
</ul>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211245700.png" alt="image-20200220211245700"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211259349.png" alt="image-20200220211259349"></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211311916.png" alt="image-20200220211311916"></p>
<ul>
<li><p>等待启动完毕，不用担心警告，后期可以调整，搭建完成，可以在展示页面进行查看集群状态。</p>
</li>
<li><p>可以查看监控界面，可以看到大数据组件中出现错误，单个组件点开处理，由于本次搭建集群使用虚拟机，性能不好，可以少选择一些组件。</p>
</li>
</ul>
<h1 id="安装问题整理"><a href="#安装问题整理" class="headerlink" title="安装问题整理"></a>安装问题整理</h1><h2 id="python-版本问题"><a href="#python-版本问题" class="headerlink" title="python 版本问题"></a>python 版本问题</h2><ul>
<li>python3环境运行报错，改成python2</li>
</ul>
<p><code>vi /usr/bin/hdp-select</code></p>
<p><img src="/2020/02/20/Apache-Ambari-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/image-20200220211348465.png" alt="image-20200220211348465"></p>
<h2 id="openssl版本的问题："><a href="#openssl版本的问题：" class="headerlink" title="openssl版本的问题："></a>openssl版本的问题：</h2><ul>
<li>EOF occurred in violation of protocol</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">INFO 2018-08-09 16:39:42,666 NetUtil.py:70 - Connecting to https://xxxx:8440/ca</span><br><span class="line">ERROR 2018-08-09 16:39:42,669 NetUtil.py:96 - EOF occurred in violation of protocol (_ssl.c:579)</span><br><span class="line">ERROR 2018-08-09 16:39:42,669 NetUtil.py:97 - SSLError: Failed to connect. Please check openssl library versions.</span><br><span class="line">Refer to: https://bugzilla.redhat.com/show_bug.cgi?id=1022468 for more details.</span><br><span class="line">WARNING 2018-08-09 16:39:42,669 NetUtil.py:124 - Server at https://xxxx:8440 is not reachable, sleeping for 10 seconds...</span><br><span class="line">INFO 2018-08-09 16:39:52,669 NetUtil.py:70 - Connecting to https://xxxx:8440/ca</span><br><span class="line">ERROR 2018-08-09 16:39:52,672 NetUtil.py:96 - EOF occurred in violation of protocol (_ssl.c:579)</span><br><span class="line">ERROR 2018-08-09 16:39:52,672 NetUtil.py:97 - SSLError: Failed to connect. Please check openssl library versions.</span><br><span class="line">Refer to: https://bugzilla.redhat.com/show_bug.cgi?id=1022468 for more details.</span><br><span class="line">WARNING 2018-08-09 16:39:52,672 NetUtil.py:124 - Server at https://xxxx:8440 is not reachable, sleeping for 10 seconds...</span><br></pre></td></tr></table></figure>

<ul>
<li>在集群中所有的节点中修改配置文件, 更改协议.<code>vi /etc/ambari-agent/conf/ambari-agent.ini</code>中加入</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[security]</span><br><span class="line">force_https_protocol=PROTOCOL_TLSv1_2</span><br></pre></td></tr></table></figure>

<ul>
<li>然后重启ambari-agent.</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>Ambari</tag>
        <tag>大数据</tag>
        <tag>Centos7</tag>
        <tag>HDP</tag>
      </tags>
  </entry>
  <entry>
    <title>ChainLink、预言机与两个世界的连接</title>
    <url>/2020/02/20/ChainLink-the-oracle-connecting-the-two-worlds/</url>
    <content><![CDATA[<p>互联网诞生之后，人们有现实世界，也有了互联网世界。如今，人们又有了一个新的世界：加密世界。这是区块链带给人们的礼物。</p>
<p>在过去二十多年，创新者们不断融合着现实和互联网世界，两者相互融入，难以分开。在比特币诞生后十多年后，加密世界也加快了跟现实世界交互的脚步。从蓝狐笔记的角度，加密世界和现实世界的融合会是未来二十年最重要的发展线之一，可以与人工智能和物联网并驾齐驱。</p>
<a id="more"></a>

<h2 id="加密世界vs-现实世界"><a href="#加密世界vs-现实世界" class="headerlink" title="加密世界vs 现实世界"></a><strong>加密世界vs 现实世界</strong></h2><p>纯粹的加密世界跟现实世界有不同的运行逻辑。</p>
<p>加密世界运行在链上，通过共识机制、密码学以及分布式节点等来保证其不可篡改性，实现不依赖于第三方的信任。智能合约运行在链上，同样，没人可以修改其代码，也无法干扰其运行，这包括智能合约的创建者。在智能合约中，其执行逻辑是，如果发生了x，那么就会执行y，这里的结果是确定性的。智能合约可以自我验证自我执行，它代表了加密世界的可信赖。</p>
<p>而在现实世界中，很难有全局的确定性共识，充满各种不确定的可能，例如应用是可以被修改、被终止的。在这种情况下，加密世界和现实世界的融合存在挑战。互联网世界可以将现实世界的部分搬到网上，例如将报纸杂志搬到网上，成为新媒体；将各种线下的零售店搬到网上就变成了网店。而加密世界跟现实世界的融合更复杂。</p>
<p>那么，两个世界如何沟通？有没有可能沟通？这就是预言机存在的意义。蓝狐笔记之前介绍了DeFi领域中的交易协议Uniswap（《<a href="http://mp.weixin.qq.com/s?__biz=MzAwOTk1NjM0NQ==&mid=2247488923&idx=1&sn=98af351abb121ad6834b7e6b70022fcc&chksm=9b56eb0dac21621bf4e59658630cb93b32f00fd80b0a751cde7ca92325cf9654c3cf9718348d&scene=21#wechat_redirect" target="_blank" rel="noopener">一文读懂Uniswap</a>》）和Kyber（《<a href="http://mp.weixin.qq.com/s?__biz=MzAwOTk1NjM0NQ==&mid=2247488932&idx=1&sn=ad78289ddcc89f682b8e5befa94648eb&chksm=9b56eb32ac2162242ae4e9d0587ad5dcc1446043a6fca7a8980e14a82e87af052a997c6ab1b2&scene=21#wechat_redirect" target="_blank" rel="noopener">Kyber的淡出与起势</a>》）。今天蓝狐笔记介绍DeFi中的预言机领域。</p>
<h2 id="预言机连通加密世界和现实世界"><a href="#预言机连通加密世界和现实世界" class="headerlink" title="预言机连通加密世界和现实世界"></a><strong>预言机连通加密世界和现实世界</strong></h2><p>加密世界和现实世界的沟通需要预言机。在蓝狐笔记看来，预言机是连接两个不同世界的“中间件”。</p>
<p>如果加密世界仅仅满足于货币类应用，那么，仅仅通过加密世界内部也可以完成，例如比特币的交易。但，如果想要更丰富的服务，想要满足更多的需求，想要将智能合约的潜力发挥到最大，那么，很有必要为智能合约引入来自现实世界的数据。</p>
<p>有人会问，为什么区块链不直接获取这些数据？无法直接获取。上面也提到过，因为这两个世界的运行逻辑不同。区块链上的数据都是通过共识机制达成的全局共识，而现实世界的数据并非都是共识的结果。两个世界的连通需要可靠的预言机。通过预言机提供可信的数据，转换成为区块链可读可用的数据。</p>
<p>加密世界需要哪些现实世界的数据？从目前发展看，迄今为止，需求最大的是DeFi领域，DeFi中MakerDAO、Compound、Synthetix、dYdX等都需要预言机提供的价格数据流服务。</p>
<p>随着智能合约的发展，会有更多的场景需要链外的数据。例如合成资产智能合约，可能需要来自于纳斯达克、纽交所的价格数据流；房产智能合约，可能需要来房地产市场的数据流；保险智能合约，例如航班延误险需要航班活动的数据流；贸易金融智能合约，可能需要获取GPS相关数据等。此外，随着人工智能和物联网的发展，智能合约对现实世界数据的需求只会越来越大。</p>
<p>除了将现实世界数据引入加密世界，加密世界的数据也可以进入现实世界。例如从链上向链下输出数据，以支付消息的形式被路由到支付网络等。</p>
<h2 id="安全是预言机的关键"><a href="#安全是预言机的关键" class="headerlink" title="安全是预言机的关键"></a><strong>安全是预言机的关键</strong></h2><p>对预言机来说，中心化或去中心化不是目的，其目的是要实现安全的可靠的数据送达服务。（从蓝狐笔记的角度，“去中心化”这个词并不是很好的表达，“分散化”或“分布式”是更恰当的描述，因为从目前实践来看，没有真正的去中心化，只是节点更多更分散而已）</p>
<p>智能合约的代码逻辑执行中，一旦发生了X，就会触发Y。这种方式保证了可信赖、透明；但是，如果输入的数据是错误的，那么，也会带来损失。就像上面提到的Synthetix案例一样，由于其输入的韩元价格数据是正常价格的1000多倍，导致产生严重后果。Synthetix是合成资产交易平台，用户通过抵押SNX代币生成合成资产。合成资产可以是BTC、ETH这些加密货币，也可以是特斯拉股票、大宗商品等。不管是加密货币还是股票、黄金，Synthetix的合成资产交易都需要精确的资产价格数据流。一旦价格数据出现问题，后果不堪设想。</p>
<p>同样，MakerDAO协议中用户使用ETH进行抵押，可以生成稳定币Dai，其抵押率在150%以上，假如输入的ETH数据是恶意的，它导致大多数用户资产被清算，且还有14%的罚金。如发生这种极端情况，MakerDAO系统将无法运行下去。同样，Compound、dYdX等DeFi项目也是如此，都需要预言机提供正确的价格数据流，以保证其系统安全。</p>
<p>可以说，预言机是DeFi领域大多数项目的共同问题（Uniswap除外，它无须预言机提供价格数据服务）。如果没有安全的预言机，DeFi大厦就没有稳固的地基，也无法扩展壮大。目前DeFi已经锁定超过6.8亿美元价值的资产，且还在持续发展中，如果预言机出问题，几乎是不可承受之重。</p>
<p>既然中心化预言机有潜在安全问题，那么，如何获得更安全的预言机服务？关于这一点，ChainLink早在2017年就提出来了，不得不说，这在当时是具有远见卓识的，毕竟2017年DeFi还没有发展起来，预言机的需求也不明显。</p>
<h2 id="ChainLink预言机如何连接两个世界"><a href="#ChainLink预言机如何连接两个世界" class="headerlink" title="ChainLink预言机如何连接两个世界"></a><strong>ChainLink预言机如何连接两个世界</strong></h2><p>上述可以得出两点：一是，预言机是加密世界和现实世界实现沟通的不可或缺的“中间件”。这决定了其重要地位，会有越来越大的市场规模。二是，预言机安全非常重要，它是很多智能合约，尤其是DeFi大厦的基础构建块，安全是其安身立命之本。</p>
<p>那么，ChainLink是如何来连接加密世界和现实世界的？</p>
<p><img src="/2020/02/20/ChainLink-the-oracle-connecting-the-two-worlds/image-20200220171328504.png" alt="image-20200220171328504"></p>
<center>（ChainLink的ETH/USD价格数据流，21个节点提供服务）</center>
### **ChainLink预言机的工作流程**

<p>ChainLink预言机的工作流程大致有如下几步：</p>
<ul>
<li>用户智能合约（USER-SC）从链上发出请求</li>
<li>ChainLink智能合约（CHAINLINK-SC）为预言机记录一个事件</li>
<li>ChainLink Core接到事件，并路由任务，给到适配器</li>
<li>ChainLink适配器向外部API发出请求</li>
<li>ChainLink适配器处理响应，并将其返回给Core</li>
<li>ChainLink Core将数据报告给ChainLink智能合约（CHAINLINK-SC）</li>
<li>ChainLink智能合约汇总响应，加权得出一个最终反馈，并将其发送给用户智能合约</li>
</ul>
<p><img src="/2020/02/20/ChainLink-the-oracle-connecting-the-two-worlds/image-20200220171538145.png" alt="image-20200220171538145"></p>
<center>（来源于ChainLink白皮书）</center>
ChainLink目前以太坊为主构建，未来也会支持其他智能合约平台，例如跟物联网公链IoTeX和分片公链Harmony等都有合作。

<p>为了实现上述工作流程，ChainLink从架构上可以分为两个部分：链上部分和链下部分。</p>
<h3 id="ChainLink的加密世界部分"><a href="#ChainLink的加密世界部分" class="headerlink" title="ChainLink的加密世界部分"></a><strong>ChainLink的加密世界部分</strong></h3><p>ChainLink智能合约响应用户智能合约的数据请求或查询。它包括三个组成合约：声誉合约、订单匹配合约以及汇总合约。其中声誉合约记录的是预言机服务提供者的历史表现；订单匹配合约通过SLA（Service Level Agreement，服务水平协议）为预言机需求者提供选择，例如价格水平、预言机数量、声誉等，并根据需求确定预言机服务提供者；汇总合约汇总不同预言机的响应，并加权计算出最终结果。</p>
<p>总的来说，ChainLink链上的工作流有三步：一是，选择预言机；二是，报告数据；三是，汇总得出结果。</p>
<p>用户选择预言机主要是通过指定SLA提案，可以选择查询参数、预言机数量、声誉情况、价格水平等。根据这些，可以进行排序、过滤，最后作出选择。确定SLA提案之后，它会被提交到订单匹配智能合约，满足SLA要求的ChainLink节点选择是否对提案出价。如果预言机服务提供者出价，则会被提交至合约，同时附上质押金，如有不当行为，会被没收。一旦SLA接收到足够多的符合要求的出价，出价窗口关闭，并从这个出价池选择最终的预言机服务者。没被选上的则其押金会被退还。</p>
<p>一旦执行SLA任务的预言机被选定，接下来就是链下的预言机执行协议，并向链上报告数据。当预言机合约收到预言机提交的结果后，这些结果会被反馈到汇总合约。汇总合约计算加权结果，得出最终的反馈答案。加权答案会返回给用户智能合约，从而触发特定功能。同时，每个预言机响应的有效性都会反馈给声誉合约。</p>
<p>当然，这个汇总加权处理方式可以有多种。有的需要在进行汇总前将异常值去掉，比如可以抛弃离散值，比如在计算时，去掉最大和最小的值，并输出剩余值的中位数等。</p>
<h3 id="ChainLink的现实世界部分"><a href="#ChainLink的现实世界部分" class="headerlink" title="ChainLink的现实世界部分"></a><strong>ChainLink的现实世界部分</strong></h3><p>ChainLink的现实世界部分，也就是其链下部分，主要由预言机节点网络组成，这些节点连接到公链（如以太坊网络）。这些节点独立收集来自现实世界数据源的数据，以响应链上请求的需求。</p>
<p>ChainLink Core 节点软件负责与区块链交互，CHainLink节点的工作是完成各种任务。每个任务有一组小的子任务。每个子任务执行特定任务，然后将其结果传递到下一个子任务，由此得到最终结果。ChainLink节点软件内置了一些子任务，包括HTTP请求、JSON解析、转换为各种区块链格式等。</p>
<p>除内置子任务类型，通过创建适配器也可以自定义子任务。适配器是具有最小REST API的外部服务。通过以面向服务的方式对适配器建模，只需在程序前添加小的中间API，可实现任何编程语言的程序。很多适配器都是开源的，服务可以审计，且由不同的社区成员运行。各种不同的适配器由不同的开发者开发，确保适配器之间的兼容也关键。ChainLink与基于JSON模式的模式系统一起使用，以指定每个适配器需要什么输入以及如何来格式化它们。</p>
<h3 id="分散化是ChainLink实现安全连接的基础"><a href="#分散化是ChainLink实现安全连接的基础" class="headerlink" title="分散化是ChainLink实现安全连接的基础"></a><strong>分散化是ChainLink实现安全连接的基础</strong></h3><p>实现预言机本身并不算很难，难的是提供持续安全的预言机服务。上面蓝狐笔记也提到过，中心化预言机面临的难题包括单点失败、数据保密、数据不被篡改等。为了实现安全的预言机，去中心化的方式，也就是分散化的方式是实现安全的基础探索。</p>
<p>针对预言机可能出现的安全漏洞，ChainLink提出了去中心化为主的安全方法，其本质也就是分散化，其中包括数据源的去中心化、预言机节点的去中心化。当然只有去中心化还不够，ChainLink还考虑了使用可信硬件、对数据源数据进行签名等方法来确保安全。</p>
<p>首先是数据源的去中心化。如果只有一个数据源，一旦该数据源被黑客篡改、或停机等，那么预言机就不安全。分散化是一种解决方案。可以通过多个来源的数据，获得多个反馈，以分散风险。</p>
<p>其次是预言机节点的去中心化。不同的预言机节点可以从一个或多个数据源获取数据，同时也可防止部分恶意节点输入错误数据。即便其中部分预言机存在错误，只要通过ChainLink汇总合约的加权计算，也有机会得出更可靠的响应。</p>
<p>不过，这里存在搭便车问题。有的节点可能会为了节省收集数据成本，抄袭其他节点的响应数据，不仅对其他节点不公平，同时也实质上降低了预言机节点数据源的分散化，从而不利于安全。ChainLink会采用加密提交方式，由预言机节点发送加密的响应到CHAINLINK-SC智能合约，在达到一定数量，并发起第二轮时才会揭示反馈值。</p>
<p>ChainLink开始时采用的是合约内汇总的方式，长期来说会采用链外汇总的方式。合约内汇总的问题是成本问题，它会涉及链上预言机消息传输和处理的成本。如果节点多，这里可能会有很高的成本。更省钱的方法是在链外执行反馈的汇总，然后向CHAINLINK-SC发送一条消息。ChainLink还提出使用门限签名的方法（蓝狐笔记：threshold signature），例如使用Schnorr签名。链外汇总的系统利用了基于门限签名的分布式协议，可以防止f&lt;n/3预言机的搭便车抄袭情况。</p>
<h3 id="ChainLink实现预言机安全的其他措施"><a href="#ChainLink实现预言机安全的其他措施" class="headerlink" title="ChainLink实现预言机安全的其他措施"></a><strong>ChainLink实现预言机安全的其他措施</strong></h3><p>仅有去中心化（分散化）的方式，还无法实现全面的安全。ChainLink还考虑其他的措施，例如包括可信硬件、来源数据的数字签名、以及其安全服务。</p>
<p>可信硬件和数字签名方面是ChainLink实现预言机安全长期要做的事情。下面主要介绍在早期预言机服务中，ChainLink为提高安全的措施，也就是其主要安全服务，其中包括：验证系统、声誉系统、认证服务、合约升级服务。</p>
<p>首选看验证系统。ChainLink验证系统监控链上预言机的行为，并提供指标，帮助用户做选择。指标包括可用性和正确性。可用性主要记录预言机没有即时响应查询的失败次数。正确性就是指正确的响应。如果偏离值大，可以比较其他节点的响应得出。在链上处理汇总数据时，预言机的活动是可见的，不过在链下执行汇总时，就无法直接观察其可用性和正确性。对于链下反馈的正确性方面，ChainLink要求预言机对其响应进行数字签名，而其他节点可以报告有明显错误的行为（举报偏离值过大的节点），报告节点会获得奖励。可用性比较难监控，ChainLink要求预言机对从其他预言机收到的反馈结果进行数字签名的证明，也就是让别人来证明自己的成功率。验证合约会接受这些证明。</p>
<p>其次是声誉系统。声誉系统主要记录历史表现。主要包括：分配的请求总数（完成响应和未完成响应的）；已完成的请求总数，可以计算出完成的成功率；被接受的请求总数，通过计算被合约接受的请求总数，然后跟其他节点做比较，并与总完成的请求总数对比，由此得出准确率；平均响应时间：它基于完成的请求来计算；质押金额：被锁定的罚金数额，可以计算节点的犯错成本。为了获得好声誉，节点会正确行事。</p>
<p>最后是认证服务。认证服务主要是为高质量的预言机提供者做信用背书。不过这会被人们误认为是许可节点参与的意思。这种服务在早期为了获得安全存在的一定的必要性。当然长期看，能否找到更合适的方法也值得考虑。认证服务会监控验证系统的数据统计，尤其对高价值交易的响应进行审计，还有链下审计，包括事后审计等。同时，这么做也是考虑了女巫和镜像攻击的可能性。女巫攻击会通过控制预言机池，提供错误数据，影响最终答案。为减少操作成本，女巫攻击者还会采用镜像，这些恶意预言机会在链下共享数据，假装有独立数据源，这样结果是减少了数据源的分散化，降低了安全。长期看，这可以通过使用可信硬件来解决。短期则需要一些认证措施。</p>
<h2 id="ChainLink的价值从何而来"><a href="#ChainLink的价值从何而来" class="headerlink" title="ChainLink的价值从何而来"></a><strong>ChainLink的价值从何而来</strong></h2><p>LINK代币是其预言机数据交易市场的支付媒介，同时也是工作权利代币。ChainLink网络使用LINK代币向节点运行者支付费用，以获得节点提供的链下数据流中检索数据的服务、将数据格式化为区块链可读格式、链外计算、以及保证正常运行。用户智能合约为了使用ChainLink预言机节点，它们也需要向其所选的ChainLink节点支付运营费用。</p>
<p>由此可见，LINK的价值来源于ChainLink预言机服务市场的规模。</p>
<h2 id="去中心化预言机市场的潜力"><a href="#去中心化预言机市场的潜力" class="headerlink" title="去中心化预言机市场的潜力"></a><strong>去中心化预言机市场的潜力</strong></h2><p>去中心化预言机领域有多大？智能合约承载价值的规模越大，去中心化预言机的需求也就越大。假如Maker、Compound、dydx等DeFi项目的规模达到几十亿上百亿美元时，预言机安全的重要性可想而知，它需要更多的节点参与，更多的数据来源参与，更安全的技术基础（如数据加密和可信硬件等）设施参与，更多预言机安全方案的探索。</p>
<p>对于有数十亿上百亿规模的价值来说，其中几千万美元甚至几亿美元用来保证其安全也是值得的。支付给预言机的服务成本，其本质是安全成本。随着合成资产等衍生品市场的发展，这个市场有可能比现货市场的规模更大，所以，对安全的预言机服务的需求也会越来越大。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a><strong>结语</strong></h2><p>预言机是连通加密世界和现实世界的“中间件”。它关系到加密领域的可持续发展，尤其是对DeFi领域来说，其重要性显而易见。</p>
<p>而对预言机来说，最核心的是安全问题。只有解决了安全问题，它才有立身之本。在解决安全问题的方法中，去中心化是达成安全的重要方式。ChainLink提出了一系列的解决方案，包括数据来源的去中心化、预言机的去中心化、可信硬件、对数据的签名，以及安全服务措施（验证、声誉、认证、合约升级）等。它为人们在去中心化预言机领域的探索开启了一条道路。</p>
<p>同时，也有人认为ChainLink的去中心化程度还不够，在安全上还有提升空间。那么，不妨更多的预言机网络进来探索，以提供更多选择。接下来蓝狐笔记如有机会将关注预言机领域的其他选手。也许未来不只有ChainLink，还会有其他预言机网络也会随着智能合约应用的兴起而发展壮大。这个领域不会只有一家选手，随着市场增长，只要能够实现更安全的预言机，机会还有，格局未定。</p>
]]></content>
      <categories>
        <category>区块链</category>
        <category>预言机</category>
        <category>DeFi</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>预言机</tag>
        <tag>ChainLink</tag>
        <tag>DeFi</tag>
      </tags>
  </entry>
</search>
